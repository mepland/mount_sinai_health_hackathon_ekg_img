{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "For reference see [Finetuning Torchvision Models](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html)  \n",
    "For additional pretrained models see [rwightman/pytorch-image-models](https://github.com/rwightman/pytorch-image-models), in particular the [README model list](https://github.com/rwightman/pytorch-image-models#ported-weights), [EfficientNet generator](https://github.com/rwightman/gen-efficientnet-pytorch/blob/master/geffnet/gen_efficientnet.py), and [pretrained weights](https://github.com/rwightman/pytorch-image-models/releases/tag/v0.1-weights)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys\n",
    "get_ipython().system('{sys.executable} -m pip install --upgrade pip');\n",
    "get_ipython().system('{sys.executable} -m pip install -r ../requirements.txt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "sys.path.append(os.path.expanduser('~/mount_sinai_health_hackathon_ekg_img/'))\n",
    "sys.path.append(os.path.expanduser('~/mount_sinai_health_hackathon_ekg_img/modeling'))\n",
    "from common_code import *\n",
    "%matplotlib inline\n",
    "\n",
    "import timm # pretrained models from rwightman/pytorch-image-models\n",
    "import torchvision.models as models # pretrained models from pytorch\n",
    "from mobilenetv3 import MobileNetV3 # mobilenetv3 definition\n",
    "\n",
    "from torchsummary import summary, summary_string\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if gpu support is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dx_classes = {\n",
    "'Normal': 'Normal sinus rhythm',\n",
    "'AF': 'Atrial fibrillation',\n",
    "'I-AVB': 'First-degree atrioventricular block',\n",
    "'LBBB': 'Left bundle branch block',\n",
    "# 'PAC': 'Premature atrial complex',\n",
    "# 'PVC': 'Premature ventricular complex',\n",
    "'RBBB': 'Right bundle branch block',\n",
    "'STD': 'ST-segment depression',\n",
    "'STE': 'ST-segment elevation',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to choose from [mobilenetv3_small_dev, tf_efficientnet_b7_ns, tf_efficientnet_b6_ns, resnet, alexnet, vgg, squeezenet, densenet]\n",
    "\n",
    "model_name = 'mobilenetv3_small_dev' # Any dimension, tested at 600\n",
    "# model_name = 'tf_efficientnet_b7_ns' # 600\n",
    "# model_name = 'tf_efficientnet_b6_ns' # 528\n",
    "# model_name = 'resnet' # 224\n",
    "\n",
    "# resume training on a prior model\n",
    "resume_training = False\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have, and how large the model is)\n",
    "batch_size = 32 # 40\n",
    "\n",
    "# balance classes by reweighting in loss function\n",
    "balance_class_weights = True\n",
    "\n",
    "# use pretrained model, should probably remain True.\n",
    "use_pretrained=False # True\n",
    "\n",
    "# Flag for feature extraction. When True only update the reshaped layer params, when False train the whole model from scratch. Should probably remain True.\n",
    "feature_extract = False\n",
    "\n",
    "# Number of classes in the dataset\n",
    "n_classes = len(Dx_classes.keys())\n",
    "\n",
    "# path to data dir\n",
    "data_path = os.path.expanduser('~/mount_sinai_health_hackathon_ekg_img/data')\n",
    "\n",
    "# channels of preprocessed images to use, 1 or 3\n",
    "im_channels=1\n",
    "\n",
    "# resolution of preprocessed images\n",
    "im_res = 800\n",
    "# im_res = 600\n",
    "\n",
    "# training settings\n",
    "do_es=True\n",
    "es_min_val_per_improvement=0.0005\n",
    "es_epochs=10\n",
    "do_decay_lr=False\n",
    "# initial_lr=0.001\n",
    "# lr_epoch_period=25\n",
    "# lr_n_period_cap=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '_dev' in model_name:\n",
    "    if use_pretrained:\n",
    "        raise ValueError('Can not use a pretrained dev model!')\n",
    "    if feature_extract and not use_pretrained:\n",
    "        raise ValueError('Can not update last feature layer for a non pretrained model!')\n",
    "else:\n",
    "    if im_channels != 3:\n",
    "        raise ValueError('Must have 3 initial color channels for most standard models!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'../output/{model_name}'\n",
    "models_path = f'../models/{model_name}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Make Training Deterministic\n",
    "See [Pytorch's Docs on Reproducibility](https://pytorch.org/docs/stable/notes/randomness.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_seed=44\n",
    "np.random.seed(rnd_seed)\n",
    "torch.manual_seed(rnd_seed+1)\n",
    "if str(device) == 'cuda':\n",
    "    torch.cuda.manual_seed(rnd_seed+2)\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathers the parameters to be optimized/updated in training. If we are finetuning we will be updating all parameters\n",
    "# However, if we are using the feature extract method, we will only update the parameters that we have just initialized,\n",
    "# i.e. the parameters with requires_grad is True.\n",
    "\n",
    "def get_parameter_requires_grad(model, feature_extracting, print_not_feature_extracting=False):\n",
    "    params_to_update = model.parameters()\n",
    "    if feature_extracting:\n",
    "        print('Params to learn:')\n",
    "        params_to_update = []\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(name)\n",
    "    else:\n",
    "        if print_not_feature_extracting:\n",
    "            print('Params to learn:')\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                if print_not_feature_extracting:\n",
    "                    print(name)\n",
    "    return params_to_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenetv3_small_dev(cfgs=None, **kwargs):\n",
    "    if cfgs is None:\n",
    "        # use original cfgs for mobilentv3 small\n",
    "         cfgs = [\n",
    "            # k, t, c, SE, HS, s\n",
    "            [3,    1,  16, 1, 0, 2],\n",
    "            [3,  4.5,  24, 0, 0, 2],\n",
    "            [3, 3.67,  24, 0, 0, 1],\n",
    "            [5,    4,  40, 1, 1, 2],\n",
    "            [5,    6,  40, 1, 1, 1],\n",
    "            [5,    6,  40, 1, 1, 1],\n",
    "            [5,    3,  48, 1, 1, 1],\n",
    "            [5,    3,  48, 1, 1, 1],\n",
    "            [5,    6,  96, 1, 1, 2],\n",
    "            [5,    6,  96, 1, 1, 1],\n",
    "            [5,    6,  96, 1, 1, 1],\n",
    "        ]\n",
    "    return MobileNetV3(cfgs, mode='small', **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, n_classes, feature_extract, use_pretrained=True):\n",
    "    model = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == 'mobilenetv3_small_dev':\n",
    "        ''' (Modified) MobileNetV3 Small\n",
    "            Paper: Searching for MobileNetV3 (https://arxiv.org/abs/1905.02244)\n",
    "        '''\n",
    "        cfgs = [\n",
    "            # k, t, c, SE, HS, s\n",
    "            [3,    1,  4, 1, 0, 2],\n",
    "            [3,  4.5,  8, 0, 0, 2],\n",
    "            [3, 3.67,  8, 0, 0, 1],\n",
    "            [5,    4,  16, 1, 1, 2],\n",
    "            [5,    6,  16, 1, 1, 1],\n",
    "            [5,    6,  30, 1, 1, 1],\n",
    "            [5,    3,  30, 1, 1, 1],\n",
    "        ]\n",
    "        model = mobilenetv3_small_dev(cfgs, num_classes=n_classes, im_channels=im_channels)\n",
    "        input_size = im_res\n",
    "    elif model_name == 'tf_efficientnet_b7_ns':\n",
    "        ''' EfficientNet-B7 NoisyStudent. Tensorflow compatible variant\n",
    "            Paper: Self-training with Noisy Student improves ImageNet classification (https://arxiv.org/abs/1911.04252)\n",
    "        '''\n",
    "        model = timm.create_model('tf_efficientnet_b7_ns', pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = model.default_cfg['input_size'][1]\n",
    "    elif model_name == 'tf_efficientnet_b6_ns':\n",
    "        ''' EfficientNet-B6 NoisyStudent. Tensorflow compatible variant\n",
    "            Paper: Self-training with Noisy Student improves ImageNet classification (https://arxiv.org/abs/1911.04252)\n",
    "        '''\n",
    "        model = timm.create_model('tf_efficientnet_b6_ns', pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = model.default_cfg['input_size'][1]\n",
    "    elif model_name == 'resnet':\n",
    "        ''' Resnet101\n",
    "        '''\n",
    "        model = models.resnet101(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == 'alexnet':\n",
    "        ''' Alexnet\n",
    "        '''\n",
    "        model = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_ftrs,n_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == 'vgg':\n",
    "        ''' VGG11_bn\n",
    "        '''\n",
    "        model = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_ftrs,n_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == 'squeezenet':\n",
    "        ''' Squeezenet\n",
    "        '''\n",
    "        model = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        model.classifier[1] = nn.Conv2d(512, n_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model.n_classes = n_classes\n",
    "        input_size = 224\n",
    "    elif model_name == 'densenet':\n",
    "        ''' Densenet\n",
    "        '''\n",
    "        model = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = 224\n",
    "    else:\n",
    "        raise ValueError(f'Invalid model_name = {model_name}')\n",
    "\n",
    "    return model, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, input_size = initialize_model(model_name, n_classes, feature_extract, use_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size = 800\n"
     ]
    }
   ],
   "source": [
    "print(f'input_size = {input_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if im_res < input_size:\n",
    "    raise ValueError(f'Warning, trying to run a model with an input size of {input_size}x{input_size} on images that are only {im_res}x{im_res}! You can proceed at your own risk, ie upscaling, better to fix one or the other size though!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = get_parameter_requires_grad(model, feature_extract, print_not_feature_extracting=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer\n",
    "optimizer = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(params_to_update, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Load Previously Trained Model\n",
    "To continue the training in another session  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume_training:\n",
    "    print('Resuming Training!')\n",
    "    dfp_train_results_prior = load_dfp(models_path, 'train_results', tag='', cols_bool=['saved_model'],\n",
    "                                       cols_float=['train_loss','val_loss','best_val_loss','delta_per_best','elapsed_time','epoch_time'])\n",
    "\n",
    "    best_epoch = dfp_train_results_prior.iloc[dfp_train_results_prior['val_loss'].idxmin()]['epoch']\n",
    "    load_model(model, device, best_epoch, model_name, models_path)\n",
    "else:\n",
    "    dfp_train_results_prior = None\n",
    "    model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Normalization Factors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dl_unnormalized = torch.utils.data.DataLoader(\n",
    "    tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/train',\n",
    "                            transform=transforms.Compose([transforms.Grayscale(num_output_channels=3), transforms.Resize(input_size), transforms.ToTensor()])),\n",
    "    batch_size=batch_size, shuffle=False, num_workers=8\n",
    ")\n",
    "\n",
    "norm_mean, norm_std0 = compute_channel_norms(dl_unnormalized)\n",
    "\n",
    "print(f\"norm_mean = [{', '.join([f'{v:.8f}' for v in norm_mean])}]\")\n",
    "print(f\"norm_std0 = [{', '.join([f'{v:.8f}' for v in norm_std0])}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use normalization results computed earlier\n",
    "if input_size == 224:\n",
    "    norm_mean = np.array([])\n",
    "    norm_std0 = np.array([])\n",
    "elif input_size == 600:\n",
    "    norm_mean = np.array([])\n",
    "    norm_std0 = np.array([])\n",
    "elif input_size == 800:\n",
    "    norm_mean = np.array([0.95817429, 0.95817429, 0.95817429])\n",
    "    norm_std0 = np.array([0.09314190, 0.09314190, 0.09314190])\n",
    "else:\n",
    "    raise ValueError(f'No precomputed mean, std available for input_size = {input_size}')\n",
    "\n",
    "if im_channels == 1:\n",
    "    norm_mean = np.array([norm_mean[0]])\n",
    "    norm_std0 = np.array([norm_std0[0]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# use normalization results used when training the model, only works for timm models. Should probably only use for color images\n",
    "norm_mean = np.array(model.default_cfg['mean'])\n",
    "norm_std0 = np.array(model.default_cfg['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_mean = [0.95817429]\n",
      "norm_std0 = [0.09314190]\n"
     ]
    }
   ],
   "source": [
    "print(f\"norm_mean = [{', '.join([f'{v:.8f}' for v in norm_mean])}]\")\n",
    "print(f\"norm_std0 = [{', '.join([f'{v:.8f}' for v in norm_std0])}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to fake 3 channels r = b = g with Grayscale to use pretrained networks\n",
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=im_channels), transforms.Resize(input_size), transforms.ToTensor(), transforms.Normalize(norm_mean, norm_std0)])\n",
    "\n",
    "ds_train = tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/train', transform=transform)\n",
    "ds_val = tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/val', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = {}\n",
    "for k,v in ds_train.class_to_idx.items():\n",
    "    class_to_idx[k] = v\n",
    "class_to_idx = dict(sorted(class_to_idx.items(), key=lambda x: x))\n",
    "idx_to_class = dict([[v,k] for k,v in class_to_idx.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_memory=True\n",
    "\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, pin_memory=pin_memory, num_workers=8)\n",
    "dl_val = torch.utils.data.DataLoader(ds_val, batch_size=batch_size, shuffle=True, pin_memory=pin_memory, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/test', transform=transform)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, pin_memory=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Setup Loss Function\n",
    "Balance class weights or leave with None, ie uniform, weights  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _count_and_weight(ds, verbose=True):\n",
    "    class_counts = torch.zeros(n_classes)\n",
    "\n",
    "    for idx in range(n_classes):\n",
    "        idx_class_tensor = torch.tensor(ds.targets) == idx\n",
    "        class_counts[idx] = idx_class_tensor.sum().item()\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Class Counts: {class_counts}')\n",
    "\n",
    "    if balance_class_weights:\n",
    "        class_weights = class_counts.sum() / class_counts\n",
    "        class_weights = class_weights / class_weights.max()\n",
    "        class_weights = class_weights.to(device)\n",
    "        if verbose:\n",
    "            print(f'Class Weights: {class_weights}')\n",
    "\n",
    "            class_counts_weighted = class_counts\n",
    "            for i in range(len(class_counts)):\n",
    "                class_counts_weighted[i] = class_weights[i]*class_counts_weighted[i]\n",
    "            print(f'Class Counts Weighted: {class_counts_weighted}')\n",
    "    else:\n",
    "        class_weights=None\n",
    "        if verbose:\n",
    "            print('Using default, ie uniform, weights')\n",
    "\n",
    "    return class_counts, class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts: tensor([2946., 1981.,  522., 2784., 4421., 2278.,  595.])\n",
      "Class Weights: tensor([0.1772, 0.2635, 1.0000, 0.1875, 0.1181, 0.2291, 0.8773],\n",
      "       device='cuda:0')\n",
      "Class Counts Weighted: tensor([522., 522., 522., 522., 522., 522., 522.])\n"
     ]
    }
   ],
   "source": [
    "class_counts_train, class_weights_train = _count_and_weight(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts: tensor([601., 377.,  99., 683., 943., 498., 138.])\n",
      "Class Weights: tensor([0.1647, 0.2626, 1.0000, 0.1449, 0.1050, 0.1988, 0.7174],\n",
      "       device='cuda:0')\n",
      "Class Counts Weighted: tensor([99.0000, 99.0000, 99.0000, 99.0000, 99.0000, 99.0000, 99.0000])\n"
     ]
    }
   ],
   "source": [
    "class_counts_val, class_weights_val = _count_and_weight(ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts: tensor([146., 102.,  26., 137., 229., 117.,  27.])\n",
      "Class Weights: tensor([0.1781, 0.2549, 1.0000, 0.1898, 0.1135, 0.2222, 0.9630],\n",
      "       device='cuda:0')\n",
      "Class Counts Weighted: tensor([26.0000, 26.0000, 26.0000, 26.0000, 26.0000, 26.0000, 26.0000])\n"
     ]
    }
   ],
   "source": [
    "class_counts_test, _ = _count_and_weight(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/nn.html#crossentropyloss\n",
    "reduction='mean' # return mean CrossEntropyLoss over batches\n",
    "loss_fn_train = nn.CrossEntropyLoss(weight=class_weights_train, reduction=reduction)\n",
    "loss_fn_val = nn.CrossEntropyLoss(weight=class_weights_val, reduction=reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs=300\n",
    "max_time_min=180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_str, (total_params, trainable_params) = summary_string(model, (1, input_size, input_size), batch_size=batch_size, device=device)\n",
    "model_eval_str = str(model.eval)\n",
    "\n",
    "model_info = {\n",
    "    'start_time': str(dt.datetime.now()),\n",
    "    'model_name': model_name,\n",
    "    'total_params': total_params.item(),\n",
    "    'trainable_params': trainable_params.item(),\n",
    "    'optimizer': str(optimizer).replace('\\n   ', ',').replace('\\n', ''),\n",
    "    'loss_fn': str(loss_fn_train),\n",
    "    'loss_fn.reduction': loss_fn_train.reduction,\n",
    "    'max_epochs': max_epochs,\n",
    "    'max_time_min': max_time_min,\n",
    "    'do_es': do_es,\n",
    "    'es_min_val_per_improvement': es_min_val_per_improvement,\n",
    "    'es_epochs': es_epochs,\n",
    "    'do_decay_lr': do_decay_lr,\n",
    "    'resume_training': resume_training,\n",
    "    'batch_size': batch_size,\n",
    "    'feature_extract': feature_extract,\n",
    "    'use_pretrained': use_pretrained,\n",
    "    'balance_class_weights': balance_class_weights,\n",
    "    'class_counts_train': ', '.join([f'{c:.0f}' for c in class_counts_train]),\n",
    "    'class_weights_train': ', '.join([f'{c:f}' for c in class_weights_train]),\n",
    "    'class_counts_val': ', '.join([f'{c:.0f}' for c in class_counts_val]),\n",
    "    'class_weights_val': ', '.join([f'{c:f}' for c in class_weights_val]),\n",
    "    'class_counts_test': ', '.join([f'{c:.0f}' for c in class_counts_test]),\n",
    "    'data_path': data_path,\n",
    "    'input_size': input_size,\n",
    "    'im_res': im_res,\n",
    "    'im_channels': im_channels,\n",
    "    'rnd_seed': rnd_seed,\n",
    "    'norm_mean': ', '.join([f'{c:f}' for c in norm_mean]),\n",
    "    'norm_std0': ', '.join([f'{c:f}' for c in norm_std0]),\n",
    "    'starting_memory': f'CUDA memory allocated: {humanize.naturalsize(torch.cuda.memory_allocated())}, cached: {humanize.naturalsize(torch.cuda.memory_cached())}',\n",
    "    'pin_memory': pin_memory,\n",
    "    'n_classes': n_classes,\n",
    "    'idx_to_class': idx_to_class,\n",
    "    'Dx_classes': Dx_classes,\n",
    "}\n",
    "\n",
    "os.makedirs(models_path, exist_ok=True)\n",
    "with open(os.path.join(models_path, 'model_info.json'), 'w') as f_json:\n",
    "    json.dump(model_info, f_json, sort_keys=False, indent=4)\n",
    "\n",
    "with open(os.path.join(models_path, 'model_summary.txt'), 'w') as f:\n",
    "    f.write(summary_str)\n",
    "    f.close()\n",
    "\n",
    "with open(os.path.join(models_path, 'model_eval.txt'), 'w') as f:\n",
    "    f.write(model_eval_str)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_train_results = train_model(dl_train, dl_val,\n",
    "model, optimizer, loss_fn_train, loss_fn_val, device,\n",
    "model_name=model_name, models_path=models_path,\n",
    "max_epochs=max_epochs, max_time_min=max_time_min,\n",
    "do_es=do_es, es_min_val_per_improvement=es_min_val_per_improvement, es_epochs=es_epochs,\n",
    "do_decay_lr=do_decay_lr, # initial_lr=0.001, lr_epoch_period=25, lr_n_period_cap=4,\n",
    "# save_model_inhibit=10, # don't save anything out for the first save_model_inhibit epochs, set to -1 to start saving immediately\n",
    "n_models_on_disk=3, # keep the last n_models_on_disk models on disk, set to -1 to keep all\n",
    "dfp_train_results_prior=dfp_train_results_prior # dfp_train_results from prior training session, use to resume\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_train_results = load_dfp(models_path, 'train_results', tag='', cols_bool=['saved_model'],\n",
    "                             cols_float=['train_loss','val_loss','best_val_loss','delta_per_best','elapsed_time','epoch_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>best_val_loss</th>\n",
       "      <th>delta_per_best</th>\n",
       "      <th>saved_model</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>epoch_time</th>\n",
       "      <th>cuda_mem_alloc</th>\n",
       "      <th>cuda_mem_cached</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.944256</td>\n",
       "      <td>1.944318</td>\n",
       "      <td>1.944318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.757764</td>\n",
       "      <td>1.757556</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.942431</td>\n",
       "      <td>1.942859</td>\n",
       "      <td>1.942859</td>\n",
       "      <td>-0.000750</td>\n",
       "      <td>True</td>\n",
       "      <td>3.469515</td>\n",
       "      <td>1.711350</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.938382</td>\n",
       "      <td>1.938904</td>\n",
       "      <td>1.938904</td>\n",
       "      <td>-0.002036</td>\n",
       "      <td>True</td>\n",
       "      <td>5.156927</td>\n",
       "      <td>1.687121</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.922001</td>\n",
       "      <td>1.923883</td>\n",
       "      <td>1.923883</td>\n",
       "      <td>-0.007747</td>\n",
       "      <td>True</td>\n",
       "      <td>6.846141</td>\n",
       "      <td>1.688931</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.764705</td>\n",
       "      <td>1.771215</td>\n",
       "      <td>1.771215</td>\n",
       "      <td>-0.079354</td>\n",
       "      <td>True</td>\n",
       "      <td>8.605715</td>\n",
       "      <td>1.759290</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.680775</td>\n",
       "      <td>1.698057</td>\n",
       "      <td>1.698057</td>\n",
       "      <td>-0.041304</td>\n",
       "      <td>True</td>\n",
       "      <td>10.349776</td>\n",
       "      <td>1.743752</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.669926</td>\n",
       "      <td>1.698540</td>\n",
       "      <td>1.698057</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>False</td>\n",
       "      <td>12.066547</td>\n",
       "      <td>1.716487</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.610062</td>\n",
       "      <td>1.639804</td>\n",
       "      <td>1.639804</td>\n",
       "      <td>-0.034305</td>\n",
       "      <td>True</td>\n",
       "      <td>13.782918</td>\n",
       "      <td>1.716287</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.586892</td>\n",
       "      <td>1.627934</td>\n",
       "      <td>1.627934</td>\n",
       "      <td>-0.007239</td>\n",
       "      <td>True</td>\n",
       "      <td>15.501307</td>\n",
       "      <td>1.718080</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.568295</td>\n",
       "      <td>1.602140</td>\n",
       "      <td>1.602140</td>\n",
       "      <td>-0.015845</td>\n",
       "      <td>True</td>\n",
       "      <td>17.192389</td>\n",
       "      <td>1.690790</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1.556777</td>\n",
       "      <td>1.620788</td>\n",
       "      <td>1.602140</td>\n",
       "      <td>0.011639</td>\n",
       "      <td>False</td>\n",
       "      <td>18.876749</td>\n",
       "      <td>1.684060</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1.494643</td>\n",
       "      <td>1.582375</td>\n",
       "      <td>1.582375</td>\n",
       "      <td>-0.012337</td>\n",
       "      <td>True</td>\n",
       "      <td>20.557990</td>\n",
       "      <td>1.681157</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1.439390</td>\n",
       "      <td>1.546953</td>\n",
       "      <td>1.546953</td>\n",
       "      <td>-0.022385</td>\n",
       "      <td>True</td>\n",
       "      <td>22.241758</td>\n",
       "      <td>1.683484</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1.441918</td>\n",
       "      <td>1.547560</td>\n",
       "      <td>1.546953</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>False</td>\n",
       "      <td>23.921055</td>\n",
       "      <td>1.679005</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1.386214</td>\n",
       "      <td>1.495626</td>\n",
       "      <td>1.495626</td>\n",
       "      <td>-0.033179</td>\n",
       "      <td>True</td>\n",
       "      <td>25.601787</td>\n",
       "      <td>1.680640</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1.362064</td>\n",
       "      <td>1.491681</td>\n",
       "      <td>1.491681</td>\n",
       "      <td>-0.002638</td>\n",
       "      <td>True</td>\n",
       "      <td>27.281985</td>\n",
       "      <td>1.679906</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1.277984</td>\n",
       "      <td>1.418501</td>\n",
       "      <td>1.418501</td>\n",
       "      <td>-0.049059</td>\n",
       "      <td>True</td>\n",
       "      <td>28.958446</td>\n",
       "      <td>1.676170</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1.262203</td>\n",
       "      <td>1.399121</td>\n",
       "      <td>1.399121</td>\n",
       "      <td>-0.013663</td>\n",
       "      <td>True</td>\n",
       "      <td>30.642839</td>\n",
       "      <td>1.684101</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1.391391</td>\n",
       "      <td>1.551571</td>\n",
       "      <td>1.399121</td>\n",
       "      <td>0.108961</td>\n",
       "      <td>False</td>\n",
       "      <td>32.322854</td>\n",
       "      <td>1.679723</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1.161884</td>\n",
       "      <td>1.317204</td>\n",
       "      <td>1.317204</td>\n",
       "      <td>-0.058549</td>\n",
       "      <td>True</td>\n",
       "      <td>34.003277</td>\n",
       "      <td>1.680340</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1.187203</td>\n",
       "      <td>1.366946</td>\n",
       "      <td>1.317204</td>\n",
       "      <td>0.037763</td>\n",
       "      <td>False</td>\n",
       "      <td>35.682775</td>\n",
       "      <td>1.679206</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1.283507</td>\n",
       "      <td>1.430205</td>\n",
       "      <td>1.317204</td>\n",
       "      <td>0.085789</td>\n",
       "      <td>False</td>\n",
       "      <td>37.360996</td>\n",
       "      <td>1.678138</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1.533681</td>\n",
       "      <td>1.716663</td>\n",
       "      <td>1.317204</td>\n",
       "      <td>0.303263</td>\n",
       "      <td>False</td>\n",
       "      <td>39.038975</td>\n",
       "      <td>1.677896</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1.015469</td>\n",
       "      <td>1.197780</td>\n",
       "      <td>1.197780</td>\n",
       "      <td>-0.090665</td>\n",
       "      <td>True</td>\n",
       "      <td>40.716246</td>\n",
       "      <td>1.677179</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1.471534</td>\n",
       "      <td>1.674888</td>\n",
       "      <td>1.197780</td>\n",
       "      <td>0.398328</td>\n",
       "      <td>False</td>\n",
       "      <td>42.397078</td>\n",
       "      <td>1.680540</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.870074</td>\n",
       "      <td>1.068967</td>\n",
       "      <td>1.068967</td>\n",
       "      <td>-0.107543</td>\n",
       "      <td>True</td>\n",
       "      <td>44.069744</td>\n",
       "      <td>1.672575</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.835235</td>\n",
       "      <td>1.018272</td>\n",
       "      <td>1.018272</td>\n",
       "      <td>-0.047425</td>\n",
       "      <td>True</td>\n",
       "      <td>45.749242</td>\n",
       "      <td>1.679206</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.782179</td>\n",
       "      <td>0.984805</td>\n",
       "      <td>0.984805</td>\n",
       "      <td>-0.032866</td>\n",
       "      <td>True</td>\n",
       "      <td>47.426162</td>\n",
       "      <td>1.676637</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.733734</td>\n",
       "      <td>0.927444</td>\n",
       "      <td>0.927444</td>\n",
       "      <td>-0.058246</td>\n",
       "      <td>True</td>\n",
       "      <td>49.106477</td>\n",
       "      <td>1.680023</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.908736</td>\n",
       "      <td>1.183005</td>\n",
       "      <td>0.927444</td>\n",
       "      <td>0.275553</td>\n",
       "      <td>False</td>\n",
       "      <td>50.785265</td>\n",
       "      <td>1.678497</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.705346</td>\n",
       "      <td>0.963930</td>\n",
       "      <td>0.927444</td>\n",
       "      <td>0.039340</td>\n",
       "      <td>False</td>\n",
       "      <td>52.464054</td>\n",
       "      <td>1.678705</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.616069</td>\n",
       "      <td>0.867149</td>\n",
       "      <td>0.867149</td>\n",
       "      <td>-0.065012</td>\n",
       "      <td>True</td>\n",
       "      <td>54.142901</td>\n",
       "      <td>1.678763</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.558735</td>\n",
       "      <td>0.819805</td>\n",
       "      <td>0.819805</td>\n",
       "      <td>-0.054598</td>\n",
       "      <td>True</td>\n",
       "      <td>55.820422</td>\n",
       "      <td>1.677229</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.600792</td>\n",
       "      <td>0.879981</td>\n",
       "      <td>0.819805</td>\n",
       "      <td>0.073403</td>\n",
       "      <td>False</td>\n",
       "      <td>57.496741</td>\n",
       "      <td>1.676028</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.492250</td>\n",
       "      <td>0.818405</td>\n",
       "      <td>0.818405</td>\n",
       "      <td>-0.001708</td>\n",
       "      <td>True</td>\n",
       "      <td>59.173445</td>\n",
       "      <td>1.676612</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.458151</td>\n",
       "      <td>0.781986</td>\n",
       "      <td>0.781986</td>\n",
       "      <td>-0.044500</td>\n",
       "      <td>True</td>\n",
       "      <td>60.862859</td>\n",
       "      <td>1.689114</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.439680</td>\n",
       "      <td>0.785400</td>\n",
       "      <td>0.781986</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>False</td>\n",
       "      <td>62.541772</td>\n",
       "      <td>1.678622</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.484232</td>\n",
       "      <td>0.844915</td>\n",
       "      <td>0.781986</td>\n",
       "      <td>0.080473</td>\n",
       "      <td>False</td>\n",
       "      <td>64.222696</td>\n",
       "      <td>1.680824</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.611687</td>\n",
       "      <td>1.005136</td>\n",
       "      <td>0.781986</td>\n",
       "      <td>0.285364</td>\n",
       "      <td>False</td>\n",
       "      <td>65.898757</td>\n",
       "      <td>1.675961</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.421994</td>\n",
       "      <td>0.809357</td>\n",
       "      <td>0.781986</td>\n",
       "      <td>0.035002</td>\n",
       "      <td>False</td>\n",
       "      <td>67.574418</td>\n",
       "      <td>1.675569</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.384096</td>\n",
       "      <td>0.749459</td>\n",
       "      <td>0.749459</td>\n",
       "      <td>-0.041596</td>\n",
       "      <td>True</td>\n",
       "      <td>69.260488</td>\n",
       "      <td>1.685978</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.339013</td>\n",
       "      <td>0.731086</td>\n",
       "      <td>0.731086</td>\n",
       "      <td>-0.024514</td>\n",
       "      <td>True</td>\n",
       "      <td>70.941345</td>\n",
       "      <td>1.680548</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.457052</td>\n",
       "      <td>0.877070</td>\n",
       "      <td>0.731086</td>\n",
       "      <td>0.199681</td>\n",
       "      <td>False</td>\n",
       "      <td>72.625062</td>\n",
       "      <td>1.683426</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.384888</td>\n",
       "      <td>0.790493</td>\n",
       "      <td>0.731086</td>\n",
       "      <td>0.081257</td>\n",
       "      <td>False</td>\n",
       "      <td>74.306028</td>\n",
       "      <td>1.680874</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.413956</td>\n",
       "      <td>0.868630</td>\n",
       "      <td>0.731086</td>\n",
       "      <td>0.188135</td>\n",
       "      <td>False</td>\n",
       "      <td>75.981305</td>\n",
       "      <td>1.675177</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.316371</td>\n",
       "      <td>0.753844</td>\n",
       "      <td>0.731086</td>\n",
       "      <td>0.031129</td>\n",
       "      <td>False</td>\n",
       "      <td>77.658576</td>\n",
       "      <td>1.677179</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.394633</td>\n",
       "      <td>0.889010</td>\n",
       "      <td>0.731086</td>\n",
       "      <td>0.216012</td>\n",
       "      <td>False</td>\n",
       "      <td>79.338790</td>\n",
       "      <td>1.680131</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.282782</td>\n",
       "      <td>0.754402</td>\n",
       "      <td>0.731086</td>\n",
       "      <td>0.031891</td>\n",
       "      <td>False</td>\n",
       "      <td>81.015118</td>\n",
       "      <td>1.676228</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.268758</td>\n",
       "      <td>0.698146</td>\n",
       "      <td>0.698146</td>\n",
       "      <td>-0.045056</td>\n",
       "      <td>True</td>\n",
       "      <td>82.690896</td>\n",
       "      <td>1.675686</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0.331638</td>\n",
       "      <td>0.835844</td>\n",
       "      <td>0.698146</td>\n",
       "      <td>0.197233</td>\n",
       "      <td>False</td>\n",
       "      <td>84.368066</td>\n",
       "      <td>1.676870</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0.286904</td>\n",
       "      <td>0.827466</td>\n",
       "      <td>0.698146</td>\n",
       "      <td>0.185233</td>\n",
       "      <td>False</td>\n",
       "      <td>86.039599</td>\n",
       "      <td>1.671441</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>0.270494</td>\n",
       "      <td>0.801067</td>\n",
       "      <td>0.698146</td>\n",
       "      <td>0.147420</td>\n",
       "      <td>False</td>\n",
       "      <td>87.718237</td>\n",
       "      <td>1.678547</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>0.224292</td>\n",
       "      <td>0.723106</td>\n",
       "      <td>0.698146</td>\n",
       "      <td>0.035752</td>\n",
       "      <td>False</td>\n",
       "      <td>89.404190</td>\n",
       "      <td>1.685853</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>0.267535</td>\n",
       "      <td>0.807048</td>\n",
       "      <td>0.698146</td>\n",
       "      <td>0.155988</td>\n",
       "      <td>False</td>\n",
       "      <td>91.091477</td>\n",
       "      <td>1.687187</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>0.280462</td>\n",
       "      <td>0.849552</td>\n",
       "      <td>0.698146</td>\n",
       "      <td>0.216868</td>\n",
       "      <td>False</td>\n",
       "      <td>92.778957</td>\n",
       "      <td>1.687388</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>0.190594</td>\n",
       "      <td>0.745547</td>\n",
       "      <td>0.698146</td>\n",
       "      <td>0.067894</td>\n",
       "      <td>False</td>\n",
       "      <td>94.469572</td>\n",
       "      <td>1.690524</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>0.190790</td>\n",
       "      <td>0.772287</td>\n",
       "      <td>0.698146</td>\n",
       "      <td>0.106197</td>\n",
       "      <td>False</td>\n",
       "      <td>96.157276</td>\n",
       "      <td>1.687604</td>\n",
       "      <td>19836928</td>\n",
       "      <td>106954752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss  best_val_loss  delta_per_best  saved_model  \\\n",
       "0       0    1.944256  1.944318       1.944318        0.000000         True   \n",
       "1       1    1.942431  1.942859       1.942859       -0.000750         True   \n",
       "2       2    1.938382  1.938904       1.938904       -0.002036         True   \n",
       "3       3    1.922001  1.923883       1.923883       -0.007747         True   \n",
       "4       4    1.764705  1.771215       1.771215       -0.079354         True   \n",
       "5       5    1.680775  1.698057       1.698057       -0.041304         True   \n",
       "6       6    1.669926  1.698540       1.698057        0.000285        False   \n",
       "7       7    1.610062  1.639804       1.639804       -0.034305         True   \n",
       "8       8    1.586892  1.627934       1.627934       -0.007239         True   \n",
       "9       9    1.568295  1.602140       1.602140       -0.015845         True   \n",
       "10     10    1.556777  1.620788       1.602140        0.011639        False   \n",
       "11     11    1.494643  1.582375       1.582375       -0.012337         True   \n",
       "12     12    1.439390  1.546953       1.546953       -0.022385         True   \n",
       "13     13    1.441918  1.547560       1.546953        0.000392        False   \n",
       "14     14    1.386214  1.495626       1.495626       -0.033179         True   \n",
       "15     15    1.362064  1.491681       1.491681       -0.002638         True   \n",
       "16     16    1.277984  1.418501       1.418501       -0.049059         True   \n",
       "17     17    1.262203  1.399121       1.399121       -0.013663         True   \n",
       "18     18    1.391391  1.551571       1.399121        0.108961        False   \n",
       "19     19    1.161884  1.317204       1.317204       -0.058549         True   \n",
       "20     20    1.187203  1.366946       1.317204        0.037763        False   \n",
       "21     21    1.283507  1.430205       1.317204        0.085789        False   \n",
       "22     22    1.533681  1.716663       1.317204        0.303263        False   \n",
       "23     23    1.015469  1.197780       1.197780       -0.090665         True   \n",
       "24     24    1.471534  1.674888       1.197780        0.398328        False   \n",
       "25     25    0.870074  1.068967       1.068967       -0.107543         True   \n",
       "26     26    0.835235  1.018272       1.018272       -0.047425         True   \n",
       "27     27    0.782179  0.984805       0.984805       -0.032866         True   \n",
       "28     28    0.733734  0.927444       0.927444       -0.058246         True   \n",
       "29     29    0.908736  1.183005       0.927444        0.275553        False   \n",
       "30     30    0.705346  0.963930       0.927444        0.039340        False   \n",
       "31     31    0.616069  0.867149       0.867149       -0.065012         True   \n",
       "32     32    0.558735  0.819805       0.819805       -0.054598         True   \n",
       "33     33    0.600792  0.879981       0.819805        0.073403        False   \n",
       "34     34    0.492250  0.818405       0.818405       -0.001708         True   \n",
       "35     35    0.458151  0.781986       0.781986       -0.044500         True   \n",
       "36     36    0.439680  0.785400       0.781986        0.004366        False   \n",
       "37     37    0.484232  0.844915       0.781986        0.080473        False   \n",
       "38     38    0.611687  1.005136       0.781986        0.285364        False   \n",
       "39     39    0.421994  0.809357       0.781986        0.035002        False   \n",
       "40     40    0.384096  0.749459       0.749459       -0.041596         True   \n",
       "41     41    0.339013  0.731086       0.731086       -0.024514         True   \n",
       "42     42    0.457052  0.877070       0.731086        0.199681        False   \n",
       "43     43    0.384888  0.790493       0.731086        0.081257        False   \n",
       "44     44    0.413956  0.868630       0.731086        0.188135        False   \n",
       "45     45    0.316371  0.753844       0.731086        0.031129        False   \n",
       "46     46    0.394633  0.889010       0.731086        0.216012        False   \n",
       "47     47    0.282782  0.754402       0.731086        0.031891        False   \n",
       "48     48    0.268758  0.698146       0.698146       -0.045056         True   \n",
       "49     49    0.331638  0.835844       0.698146        0.197233        False   \n",
       "50     50    0.286904  0.827466       0.698146        0.185233        False   \n",
       "51     51    0.270494  0.801067       0.698146        0.147420        False   \n",
       "52     52    0.224292  0.723106       0.698146        0.035752        False   \n",
       "53     53    0.267535  0.807048       0.698146        0.155988        False   \n",
       "54     54    0.280462  0.849552       0.698146        0.216868        False   \n",
       "55     55    0.190594  0.745547       0.698146        0.067894        False   \n",
       "56     56    0.190790  0.772287       0.698146        0.106197        False   \n",
       "\n",
       "    elapsed_time  epoch_time  cuda_mem_alloc  cuda_mem_cached  \n",
       "0       1.757764    1.757556        19836928        106954752  \n",
       "1       3.469515    1.711350        19836928        106954752  \n",
       "2       5.156927    1.687121        19836928        106954752  \n",
       "3       6.846141    1.688931        19836928        106954752  \n",
       "4       8.605715    1.759290        19836928        106954752  \n",
       "5      10.349776    1.743752        19836928        106954752  \n",
       "6      12.066547    1.716487        19836928        106954752  \n",
       "7      13.782918    1.716287        19836928        106954752  \n",
       "8      15.501307    1.718080        19836928        106954752  \n",
       "9      17.192389    1.690790        19836928        106954752  \n",
       "10     18.876749    1.684060        19836928        106954752  \n",
       "11     20.557990    1.681157        19836928        106954752  \n",
       "12     22.241758    1.683484        19836928        106954752  \n",
       "13     23.921055    1.679005        19836928        106954752  \n",
       "14     25.601787    1.680640        19836928        106954752  \n",
       "15     27.281985    1.679906        19836928        106954752  \n",
       "16     28.958446    1.676170        19836928        106954752  \n",
       "17     30.642839    1.684101        19836928        106954752  \n",
       "18     32.322854    1.679723        19836928        106954752  \n",
       "19     34.003277    1.680340        19836928        106954752  \n",
       "20     35.682775    1.679206        19836928        106954752  \n",
       "21     37.360996    1.678138        19836928        106954752  \n",
       "22     39.038975    1.677896        19836928        106954752  \n",
       "23     40.716246    1.677179        19836928        106954752  \n",
       "24     42.397078    1.680540        19836928        106954752  \n",
       "25     44.069744    1.672575        19836928        106954752  \n",
       "26     45.749242    1.679206        19836928        106954752  \n",
       "27     47.426162    1.676637        19836928        106954752  \n",
       "28     49.106477    1.680023        19836928        106954752  \n",
       "29     50.785265    1.678497        19836928        106954752  \n",
       "30     52.464054    1.678705        19836928        106954752  \n",
       "31     54.142901    1.678763        19836928        106954752  \n",
       "32     55.820422    1.677229        19836928        106954752  \n",
       "33     57.496741    1.676028        19836928        106954752  \n",
       "34     59.173445    1.676612        19836928        106954752  \n",
       "35     60.862859    1.689114        19836928        106954752  \n",
       "36     62.541772    1.678622        19836928        106954752  \n",
       "37     64.222696    1.680824        19836928        106954752  \n",
       "38     65.898757    1.675961        19836928        106954752  \n",
       "39     67.574418    1.675569        19836928        106954752  \n",
       "40     69.260488    1.685978        19836928        106954752  \n",
       "41     70.941345    1.680548        19836928        106954752  \n",
       "42     72.625062    1.683426        19836928        106954752  \n",
       "43     74.306028    1.680874        19836928        106954752  \n",
       "44     75.981305    1.675177        19836928        106954752  \n",
       "45     77.658576    1.677179        19836928        106954752  \n",
       "46     79.338790    1.680131        19836928        106954752  \n",
       "47     81.015118    1.676228        19836928        106954752  \n",
       "48     82.690896    1.675686        19836928        106954752  \n",
       "49     84.368066    1.676870        19836928        106954752  \n",
       "50     86.039599    1.671441        19836928        106954752  \n",
       "51     87.718237    1.678547        19836928        106954752  \n",
       "52     89.404190    1.685853        19836928        106954752  \n",
       "53     91.091477    1.687187        19836928        106954752  \n",
       "54     92.778957    1.687388        19836928        106954752  \n",
       "55     94.469572    1.690524        19836928        106954752  \n",
       "56     96.157276    1.687604        19836928        106954752  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_vs_epoch(dfp_train_results, output_path, fname='loss_vs_epoch', tag='_val', inline=False,\n",
    "                   ann_text_std_add=None,\n",
    "                   y_axis_params={'log': False},\n",
    "                   loss_cols=['val_loss'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_vs_epoch(dfp_train_results, output_path, fname='loss_vs_epoch', tag='_train', inline=False,\n",
    "                   ann_text_std_add=None,\n",
    "                   y_axis_params={'log': False},\n",
    "                   loss_cols=['train_loss'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_vs_epoch(dfp_train_results, output_path, fname='loss_vs_epoch', tag='', inline=False,\n",
    "                   ann_text_std_add=None,\n",
    "                   y_axis_params={'log': False},\n",
    "                   loss_cols=['train_loss', 'val_loss'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = dfp_train_results.iloc[dfp_train_results['val_loss'].idxmin()]['epoch']\n",
    "load_model(model, device, best_epoch, model_name, models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data again, with paths\n",
    "Non-standard but needed to see what images scored high or low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_with_paths_val = ImageFolderWithPaths(root=f'{data_path}/preprocessed/im_res_{im_res}/val', transform=transform)\n",
    "dl_with_paths_val = torch.utils.data.DataLoader(ds_with_paths_val, batch_size=batch_size, shuffle=True, pin_memory=pin_memory, num_workers=8)\n",
    "\n",
    "ds_with_paths_test = ImageFolderWithPaths(root=f'{data_path}/preprocessed/im_res_{im_res}/test', transform=transform)\n",
    "dl_with_paths_test = torch.utils.data.DataLoader(ds_with_paths_test, batch_size=batch_size, shuffle=False, pin_memory=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_preds_dfp(dl_with_paths, model, device):\n",
    "    l, p, f = get_preds(dl_with_paths, model, device, return_fnames=True)\n",
    "\n",
    "    dfp = pd.DataFrame({'label': l, 'pred': p, 'fname': f})\n",
    "\n",
    "    dfp['is_correct'] = 0\n",
    "    dfp.loc[dfp['label'] == dfp['pred'], 'is_correct'] = 1\n",
    "\n",
    "    dfp = massage_dfp(dfp, target_fixed_cols=['label', 'pred', 'is_correct', 'fname'],\n",
    "                      sort_by=['label', 'is_correct', 'pred', 'fname'], sort_by_ascending=[True, False, True, True])\n",
    "\n",
    "    return dfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_preds_val = _make_preds_dfp(dl_with_paths_val, model, device)\n",
    "write_dfp(dfp_preds_val, output_path, 'preds', tag='_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0007-s00_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0007-s01_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0007-s02_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0153-s00_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0153-s01_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>A6414-s00_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A0034-s01_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A4877-s00_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A4877-s01_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A4877-s02_PIL.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3339 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  pred  is_correct              fname\n",
       "0         0     0           1  A0007-s00_PIL.png\n",
       "1         0     0           1  A0007-s01_PIL.png\n",
       "2         0     0           1  A0007-s02_PIL.png\n",
       "3         0     0           1  A0153-s00_PIL.png\n",
       "4         0     0           1  A0153-s01_PIL.png\n",
       "...     ...   ...         ...                ...\n",
       "3334      6     4           0  A6414-s00_PIL.png\n",
       "3335      6     5           0  A0034-s01_PIL.png\n",
       "3336      6     5           0  A4877-s00_PIL.png\n",
       "3337      6     5           0  A4877-s01_PIL.png\n",
       "3338      6     5           0  A4877-s02_PIL.png\n",
       "\n",
       "[3339 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_preds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_val = confusion_matrix(y_true=dfp_preds_val['label'], y_pred=dfp_preds_val['pred'], labels=[class_to_idx[k] for k in Dx_classes.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = {'_val': True, '_raw_val': False}\n",
    "for tag,norm in cms.items():\n",
    "    plot_confusion_matrix(conf_matrix_val, label_names=Dx_classes.keys(),\n",
    "                          m_path=output_path, tag=tag, inline=False,\n",
    "                          ann_text_std_add=None,\n",
    "                          normalize=norm,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_preds_test = _make_preds_dfp(dl_with_paths_test, model, device)\n",
    "write_dfp(dfp_preds_test, output_path, 'preds', tag='_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0004-s01_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0220-s00_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0235-s01_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0376-s00_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0415-s03_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>A5863-s01_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>A1479-s02_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>A1802-s02_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>A1839-s00_PIL.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>A4200-s01_PIL.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  pred  is_correct              fname\n",
       "0        0     0           1  A0004-s01_PIL.png\n",
       "1        0     0           1  A0220-s00_PIL.png\n",
       "2        0     0           1  A0235-s01_PIL.png\n",
       "3        0     0           1  A0376-s00_PIL.png\n",
       "4        0     0           1  A0415-s03_PIL.png\n",
       "..     ...   ...         ...                ...\n",
       "779      6     3           0  A5863-s01_PIL.png\n",
       "780      6     4           0  A1479-s02_PIL.png\n",
       "781      6     4           0  A1802-s02_PIL.png\n",
       "782      6     4           0  A1839-s00_PIL.png\n",
       "783      6     4           0  A4200-s01_PIL.png\n",
       "\n",
       "[784 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_test = confusion_matrix(y_true=dfp_preds_test['label'], y_pred=dfp_preds_test['pred'], labels=[class_to_idx[k] for k in Dx_classes.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = {'_test': True, '_raw_test': False}\n",
    "for tag,norm in cms.items():\n",
    "    plot_confusion_matrix(conf_matrix_test, label_names=Dx_classes.keys(),\n",
    "                          m_path=output_path, tag=tag, inline=False,\n",
    "                          ann_text_std_add=None,\n",
    "                          normalize=norm,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_code import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_eval_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mem(print_objects=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
