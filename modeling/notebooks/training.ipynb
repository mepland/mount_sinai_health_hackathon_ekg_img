{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "For reference see [Finetuning Torchvision Models](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html)  \n",
    "For additional pretrained models see [rwightman/pytorch-image-models](https://github.com/rwightman/pytorch-image-models), in particular the [README model list](https://github.com/rwightman/pytorch-image-models#ported-weights), [EfficientNet generator](https://github.com/rwightman/gen-efficientnet-pytorch/blob/master/geffnet/gen_efficientnet.py), and [pretrained weights](https://github.com/rwightman/pytorch-image-models/releases/tag/v0.1-weights)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys\n",
    "get_ipython().system('{sys.executable} -m pip install --upgrade pip');\n",
    "get_ipython().system('{sys.executable} -m pip install -r ../requirements.txt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "sys.path.append(os.path.expanduser('~/mount_sinai_health_hackathon_ekg_img/'))\n",
    "sys.path.append(os.path.expanduser('~/mount_sinai_health_hackathon_ekg_img/modeling'))\n",
    "from common_code import *\n",
    "%matplotlib inline\n",
    "\n",
    "import timm # pretrained models from rwightman/pytorch-image-models\n",
    "import torchvision.models as models # pretrained models from pytorch\n",
    "from mobilenetv3 import MobileNetV3 # mobilenetv3 definition\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if gpu support is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dx_classes = {\n",
    "'Normal': 'Normal sinus rhythm',\n",
    "'AF': 'Atrial fibrillation',\n",
    "'I-AVB': 'First-degree atrioventricular block',\n",
    "'LBBB': 'Left bundle branch block',\n",
    "'PAC': 'Premature atrial complex',\n",
    "'PVC': 'Premature ventricular complex',\n",
    "'RBBB': 'Right bundle branch block',\n",
    "'STD': 'ST-segment depression',\n",
    "'STE': 'ST-segment elevation',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to choose from [mobilenetv3_small_dev, tf_efficientnet_b7_ns, tf_efficientnet_b6_ns, resnet, alexnet, vgg, squeezenet, densenet]\n",
    "\n",
    "model_name = 'mobilenetv3_small_dev' # Any dimension, tested at 600\n",
    "# model_name = 'tf_efficientnet_b7_ns' # 600\n",
    "# model_name = 'tf_efficientnet_b6_ns' # 528\n",
    "# model_name = 'resnet' # 224\n",
    "\n",
    "# resume training on a prior model\n",
    "resume_training = False\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have, and how large the model is)\n",
    "batch_size = 32 # 40\n",
    "\n",
    "# balance classes by reweighting in loss function\n",
    "balance_class_weights = True\n",
    "\n",
    "# use pretrained model, should probably remain True.\n",
    "use_pretrained=False # True\n",
    "\n",
    "# Flag for feature extraction. When True only update the reshaped layer params, when False train the whole model from scratch. Should probably remain True.\n",
    "feature_extract = False\n",
    "\n",
    "# Number of classes in the dataset\n",
    "n_classes = len(Dx_classes.keys())\n",
    "\n",
    "# path to data dir\n",
    "data_path = os.path.expanduser('~/mount_sinai_health_hackathon_ekg_img/data')\n",
    "\n",
    "# channels of preprocessed images to use, 1 or 3\n",
    "im_channels=1\n",
    "\n",
    "# resolution of preprocessed images\n",
    "im_res = 800\n",
    "# im_res = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '_dev' in model_name:\n",
    "    if use_pretrained:\n",
    "        raise ValueError('Can not use a pretrained dev model!')\n",
    "    if feature_extract and not use_pretrained:\n",
    "        raise ValueError('Can not update last feature layer for a non pretrained model!')\n",
    "else:\n",
    "    if im_channels != 3:\n",
    "        raise ValueError('Must have 3 initial color channels for most standard models!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'../output/{model_name}'\n",
    "models_path = f'../models/{model_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Make Training Deterministic\n",
    "See [Pytorch's Docs on Reproducibility](https://pytorch.org/docs/stable/notes/randomness.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_seed=42\n",
    "np.random.seed(rnd_seed)\n",
    "torch.manual_seed(rnd_seed+1)\n",
    "if str(device) == 'cuda':\n",
    "    torch.cuda.manual_seed(rnd_seed+2)\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathers the parameters to be optimized/updated in training. If we are finetuning we will be updating all parameters\n",
    "# However, if we are using the feature extract method, we will only update the parameters that we have just initialized,\n",
    "# i.e. the parameters with requires_grad is True.\n",
    "\n",
    "def get_parameter_requires_grad(model, feature_extracting, print_not_feature_extracting=False):\n",
    "    params_to_update = model.parameters()\n",
    "    if feature_extracting:\n",
    "        print('Params to learn:')\n",
    "        params_to_update = []\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(name)\n",
    "    else:\n",
    "        if print_not_feature_extracting:\n",
    "            print('Params to learn:')\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                if print_not_feature_extracting:\n",
    "                    print(name)\n",
    "    return params_to_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenetv3_small_dev(cfgs=None, **kwargs):\n",
    "    if cfgs is None:\n",
    "        # use original cfgs for mobilentv3 small\n",
    "         cfgs = [\n",
    "            # k, t, c, SE, HS, s\n",
    "            [3,    1,  16, 1, 0, 2],\n",
    "            [3,  4.5,  24, 0, 0, 2],\n",
    "            [3, 3.67,  24, 0, 0, 1],\n",
    "            [5,    4,  40, 1, 1, 2],\n",
    "            [5,    6,  40, 1, 1, 1],\n",
    "            [5,    6,  40, 1, 1, 1],\n",
    "            [5,    3,  48, 1, 1, 1],\n",
    "            [5,    3,  48, 1, 1, 1],\n",
    "            [5,    6,  96, 1, 1, 2],\n",
    "            [5,    6,  96, 1, 1, 1],\n",
    "            [5,    6,  96, 1, 1, 1],\n",
    "        ]\n",
    "    return MobileNetV3(cfgs, mode='small', **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, n_classes, feature_extract, use_pretrained=True):\n",
    "    model = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == 'mobilenetv3_small_dev':\n",
    "        ''' (Modified) MobileNetV3 Small\n",
    "            Paper: Searching for MobileNetV3 (https://arxiv.org/abs/1905.02244)\n",
    "        '''\n",
    "        cfgs = [\n",
    "            # k, t, c, SE, HS, s\n",
    "            [3,    1,  4, 1, 0, 2],\n",
    "            [3,  4.5,  8, 0, 0, 2],\n",
    "            [3, 3.67,  8, 0, 0, 1],\n",
    "            [5,    4,  16, 1, 1, 2],\n",
    "            [5,    6,  16, 1, 1, 1],\n",
    "            [5,    6,  30, 1, 1, 1],\n",
    "            [5,    3,  30, 1, 1, 1],\n",
    "        ]\n",
    "        model = mobilenetv3_small_dev(cfgs, num_classes=n_classes, im_channels=im_channels)\n",
    "        input_size = im_res\n",
    "    elif model_name == 'tf_efficientnet_b7_ns':\n",
    "        ''' EfficientNet-B7 NoisyStudent. Tensorflow compatible variant\n",
    "            Paper: Self-training with Noisy Student improves ImageNet classification (https://arxiv.org/abs/1911.04252)\n",
    "        '''\n",
    "        model = timm.create_model('tf_efficientnet_b7_ns', pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = model.default_cfg['input_size'][1]\n",
    "    elif model_name == 'tf_efficientnet_b6_ns':\n",
    "        ''' EfficientNet-B6 NoisyStudent. Tensorflow compatible variant\n",
    "            Paper: Self-training with Noisy Student improves ImageNet classification (https://arxiv.org/abs/1911.04252)\n",
    "        '''\n",
    "        model = timm.create_model('tf_efficientnet_b6_ns', pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = model.default_cfg['input_size'][1]\n",
    "    elif model_name == 'resnet':\n",
    "        ''' Resnet101\n",
    "        '''\n",
    "        model = models.resnet101(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == 'alexnet':\n",
    "        ''' Alexnet\n",
    "        '''\n",
    "        model = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_ftrs,n_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == 'vgg':\n",
    "        ''' VGG11_bn\n",
    "        '''\n",
    "        model = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_ftrs,n_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == 'squeezenet':\n",
    "        ''' Squeezenet\n",
    "        '''\n",
    "        model = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        model.classifier[1] = nn.Conv2d(512, n_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model.n_classes = n_classes\n",
    "        input_size = 224\n",
    "    elif model_name == 'densenet':\n",
    "        ''' Densenet\n",
    "        '''\n",
    "        model = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = 224\n",
    "    else:\n",
    "        raise ValueError(f'Invalid model_name = {model_name}')\n",
    "\n",
    "    return model, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, input_size = initialize_model(model_name, n_classes, feature_extract, use_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'input_size = {input_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if im_res < input_size:\n",
    "    raise ValueError(f'Warning, trying to run a model with an input size of {input_size}x{input_size} on images that are only {im_res}x{im_res}! You can proceed at your own risk, ie upscaling, better to fix one or the other size though!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = get_parameter_requires_grad(model, feature_extract, print_not_feature_extracting=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer\n",
    "optimizer = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "#optimizer = torch.optim.Adam(params_to_update, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Load Previously Trained Model\n",
    "To continue the training in another session  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume_training:\n",
    "    print('Resuming Training!')\n",
    "    dfp_train_results_prior = load_dfp(models_path, 'train_results', tag='', cols_bool=['saved_model'],\n",
    "                                       cols_float=['train_loss','val_loss','best_val_loss','delta_per_best','elapsed_time','epoch_time'])\n",
    "\n",
    "    best_epoch = dfp_train_results_prior.iloc[dfp_train_results_prior['val_loss'].idxmin()]['epoch']\n",
    "    load_model(model, device, best_epoch, model_name, models_path)\n",
    "else:\n",
    "    dfp_train_results_prior = None\n",
    "    model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Normalization Factors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dl_unnormalized = torch.utils.data.DataLoader(\n",
    "    tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/train',\n",
    "                            transform=transforms.Compose([transforms.Grayscale(num_output_channels=3), transforms.Resize(input_size), transforms.ToTensor()])),\n",
    "    batch_size=batch_size, shuffle=False, num_workers=8\n",
    ")\n",
    "\n",
    "norm_mean, norm_std0 = compute_channel_norms(dl_unnormalized)\n",
    "\n",
    "print(f\"norm_mean = [{', '.join([f'{v:.8f}' for v in norm_mean])}]\")\n",
    "print(f\"norm_std0 = [{', '.join([f'{v:.8f}' for v in norm_std0])}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use normalization results computed earlier\n",
    "if input_size == 224:\n",
    "    norm_mean = np.array([])\n",
    "    norm_std0 = np.array([])\n",
    "elif input_size == 600:\n",
    "    norm_mean = np.array([0.95740360, 0.95740360, 0.95740360])\n",
    "    norm_std0 = np.array([0.08236791, 0.08236791, 0.08236791])\n",
    "elif input_size == 800:\n",
    "    norm_mean = np.array([0.95808870, 0.95808870, 0.95808870])\n",
    "    norm_std0 = np.array([0.09361055, 0.09361055, 0.09361055])\n",
    "else:\n",
    "    raise ValueError(f'No precomputed mean, std available for input_size = {input_size}')\n",
    "\n",
    "if im_channels == 1:\n",
    "    norm_mean = np.array([norm_mean[0]])\n",
    "    norm_std0 = np.array([norm_std0[0]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# use normalization results used when training the model, only works for timm models. Should probably only use for color images\n",
    "norm_mean = np.array(model.default_cfg['mean'])\n",
    "norm_std0 = np.array(model.default_cfg['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"norm_mean = [{', '.join([f'{v:.8f}' for v in norm_mean])}]\")\n",
    "print(f\"norm_std0 = [{', '.join([f'{v:.8f}' for v in norm_std0])}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to fake 3 channels r = b = g with Grayscale to use pretrained networks\n",
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=im_channels), transforms.Resize(input_size), transforms.ToTensor(), transforms.Normalize(norm_mean, norm_std0)])\n",
    "\n",
    "ds_train = tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/train', transform=transform)\n",
    "ds_val = tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/val', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = {}\n",
    "for k,v in ds_train.class_to_idx.items():\n",
    "    class_to_idx[k] = v\n",
    "class_to_idx = dict(sorted(class_to_idx.items(), key=lambda x: x))\n",
    "idx_to_class = dict([[v,k] for k,v in class_to_idx.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_memory=True\n",
    "\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, pin_memory=pin_memory, num_workers=8)\n",
    "dl_val = torch.utils.data.DataLoader(ds_val, batch_size=batch_size, shuffle=True, pin_memory=pin_memory, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_test = tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/test', transform=transform)\n",
    "# dl_test = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, pin_memory=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Setup Loss Function\n",
    "Balance class weights or leave with None, ie uniform, weights  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = torch.zeros(n_classes)\n",
    "for idx in range(n_classes):\n",
    "    idx_class_tensor = torch.tensor(ds_train.targets) == idx\n",
    "    class_counts[idx] = idx_class_tensor.sum().item()\n",
    "print(f'Class Counts: {class_counts}')\n",
    "\n",
    "if balance_class_weights:\n",
    "    class_weights = class_counts.sum() / class_counts\n",
    "    class_weights = class_weights / class_weights.max()\n",
    "    class_weights = class_weights.to(device)\n",
    "    print(f'Class Weights: {class_weights}')\n",
    "\n",
    "    class_counts_weighted = class_counts\n",
    "    for i in range(len(class_counts)):\n",
    "        class_counts_weighted[i] = class_weights[i]*class_counts_weighted[i]\n",
    "    print(f'Class Counts Weighted: {class_counts_weighted}')\n",
    "else:\n",
    "    class_weights=None\n",
    "    print('Using default, ie uniform, weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/nn.html#crossentropyloss\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights, reduction='mean')\n",
    "# reduction='mean', return mean CrossEntropyLoss over batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = {\n",
    "    'start_time': str(dt.datetime.now()),\n",
    "    'model_name': model_name,\n",
    "    'optimizer': str(optimizer).replace('\\n   ', ',').replace('\\n', ''),\n",
    "    'loss_fn': str(loss_fn),\n",
    "    'loss_fn.reduction': loss_fn.reduction,\n",
    "    'resume_training': resume_training,\n",
    "    'batch_size': batch_size,\n",
    "    'feature_extract': feature_extract,\n",
    "    'use_pretrained': use_pretrained,\n",
    "    'balance_class_weights': balance_class_weights,\n",
    "    'class_counts': ', '.join([f'{c:.0f}' for c in class_counts]),\n",
    "    'class_weights': ', '.join([f'{c:f}' for c in class_weights]),\n",
    "    'data_path': data_path,\n",
    "    'input_size': input_size,\n",
    "    'im_res': im_res,\n",
    "    'im_channels': im_channels,\n",
    "    'rnd_seed': rnd_seed,\n",
    "    'norm_mean': ', '.join([f'{c:f}' for c in norm_mean]),\n",
    "    'norm_std0': ', '.join([f'{c:f}' for c in norm_std0]),\n",
    "    'starting_memory': f'CUDA memory allocated: {humanize.naturalsize(torch.cuda.memory_allocated())}, cached: {humanize.naturalsize(torch.cuda.memory_cached())}',\n",
    "    'pin_memory': pin_memory,\n",
    "    'n_classes': n_classes,\n",
    "    'idx_to_class': idx_to_class,\n",
    "    'Dx_classes': Dx_classes,\n",
    "}\n",
    "\n",
    "os.makedirs(models_path, exist_ok=True)\n",
    "with open(os.path.join(models_path, 'model_info.json'), 'w') as f_json:\n",
    "    json.dump(model_info, f_json, sort_keys=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_train_results = train_model(dl_train, dl_val,\n",
    "model, optimizer, loss_fn, device,\n",
    "model_name=model_name, models_path=models_path,\n",
    "max_epochs=300, max_time_min=180,\n",
    "do_es=True, es_min_val_per_improvement=0.0005, es_epochs=10,\n",
    "do_decay_lr=False, # initial_lr=0.001, lr_epoch_period=25, lr_n_period_cap=4,\n",
    "# save_model_inhibit=10, # don't save anything out for the first save_model_inhibit epochs, set to -1 to start saving immediately\n",
    "n_models_on_disk=3, # keep the last n_models_on_disk models on disk, set to -1 to keep all\n",
    "dfp_train_results_prior=dfp_train_results_prior # dfp_train_results from prior training session, use to resume\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_train_results = load_dfp(models_path, 'train_results', tag='', cols_bool=['saved_model'],\n",
    "                             cols_float=['train_loss','val_loss','best_val_loss','delta_per_best','elapsed_time','epoch_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_vs_epoch(dfp_train_results, output_path, fname='loss_vs_epoch', tag='_val', inline=False,\n",
    "                   ann_text_std_add=None,\n",
    "                   y_axis_params={'log': False},\n",
    "                   loss_cols=['val_loss'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_vs_epoch(dfp_train_results, output_path, fname='loss_vs_epoch', tag='_train', inline=False,\n",
    "                   ann_text_std_add=None,\n",
    "                   y_axis_params={'log': False},\n",
    "                   loss_cols=['train_loss'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_vs_epoch(dfp_train_results, output_path, fname='loss_vs_epoch', tag='', inline=False,\n",
    "                   ann_text_std_add=None,\n",
    "                   y_axis_params={'log': False},\n",
    "                   loss_cols=['train_loss', 'val_loss'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = dfp_train_results.iloc[dfp_train_results['val_loss'].idxmin()]['epoch']\n",
    "load_model(model, device, best_epoch, model_name, models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, preds = get_preds(dl_val, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true=labels, y_pred=preds, labels=[class_to_idx[k] for k in Dx_classes.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = {'_val': True, '_raw_val': False}\n",
    "for tag,norm in cms.items():\n",
    "    plot_confusion_matrix(conf_matrix, label_names=Dx_classes.keys(),\n",
    "                          m_path=output_path, tag=tag, inline=False,\n",
    "                          ann_text_std_add=None,\n",
    "                          normalize=norm,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_code import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mem(print_objects=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
