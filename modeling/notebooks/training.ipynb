{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "For reference see [Finetuning Torchvision Models](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys\n",
    "get_ipython().system('{sys.executable} -m pip install --upgrade pip');\n",
    "get_ipython().system('{sys.executable} -m pip install -r ../requirements.txt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "sys.path.append(os.path.expanduser('~/mount_sinai_health_hackathon_ekg_img/'))\n",
    "from common_code import *\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "# from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dx_classes = {\n",
    "'Normal': 'Normal sinus rhythm',\n",
    "'AF': 'Atrial fibrillation',\n",
    "'I-AVB': 'Airst-degree atrioventricular block',\n",
    "'LBBB': 'Left bundle branch block',\n",
    "'PAC': 'Premature atrial complex',\n",
    "'PVC': 'Premature ventricular complex',\n",
    "'RBBB': 'Right bundle branch block',\n",
    "'STD': 'ST-segment depression',\n",
    "'STE': 'ST-segment elevation',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if gpu support is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = 'resnet'\n",
    "\n",
    "# Number of classes in the dataset\n",
    "n_classes = len(Dx_classes.keys())\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 256\n",
    "\n",
    "# Flag for feature extraction. When True only update the reshaped layer params, when False train the whole model from scratch.\n",
    "# Should probably remain True.\n",
    "feature_extract = True\n",
    "\n",
    "# use pretrained model, should probably remain True.\n",
    "use_pretrained=True\n",
    "\n",
    "# path to data dir\n",
    "data_path = os.path.expanduser('~/mount_sinai_health_hackathon_ekg_img/data')\n",
    "\n",
    "# resolution of preprocessed images\n",
    "im_res = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'../output/{model_name}'\n",
    "models_path = f'../models/{model_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, n_classes, feature_extract, use_pretrained=True):\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == 'resnet':\n",
    "        ''' Resnet101\n",
    "        '''\n",
    "        model_ft = models.resnet101(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'alexnet':\n",
    "        ''' Alexnet\n",
    "        '''\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,n_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'vgg':\n",
    "        ''' VGG11_bn\n",
    "        '''\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,n_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'squeezenet':\n",
    "        ''' Squeezenet\n",
    "        '''\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, n_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.n_classes = n_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'densenet':\n",
    "        ''' Densenet\n",
    "        '''\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = 224\n",
    "\n",
    "#    elif model_name == 'inception':\n",
    "#        ''' Inception v3\n",
    "#        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "#        '''\n",
    "#        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "#        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "#        # Handle the auxilary net\n",
    "#        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "#        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, n_classes)\n",
    "#        # Handle the primary net\n",
    "#        num_ftrs = model_ft.fc.in_features\n",
    "#        model_ft.fc = nn.Linear(num_ftrs,n_classes)\n",
    "#        input_size = 299\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'Invalid model_name = {model_name}')\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, input_size = initialize_model(model_name, n_classes, feature_extract, use_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'input_size = {input_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO is all of this needed?\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run.\n",
    "# If we are finetuning we will be updating all parameters\n",
    "# However, if we are usingthe  feature extract method, we will only update the parameters that we have just initialized,\n",
    "# i.e. the parameters with requires_grad is True.\n",
    "\n",
    "params_to_update = model.parameters()\n",
    "print('Params to learn:')\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(name)\n",
    "else:\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(params_to_update, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Normalization Factors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dl_unnormalized = torch.utils.data.DataLoader(\n",
    "    tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/all',\n",
    "                            transform=transforms.Compose([transforms.Resize(input_size), transforms.ToTensor()])),\n",
    "    batch_size=batch_size, shuffle=False, num_workers=8\n",
    ")\n",
    "\n",
    "pop_mean, pop_std0 = compute_channel_norms(dl_unnormalized)\n",
    "\n",
    "print(f'pop_mean = {pop_mean}')\n",
    "print(f'pop_std0 = {pop_std0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use normalization results computed earlier\n",
    "if input_size == 224:\n",
    "    pop_mean = np.array([0.94411284, 0.94346404, 0.94239646])\n",
    "    pop_std0 = np.array([0.04548508, 0.04374889, 0.04681061])\n",
    "else:\n",
    "    raise ValueError(f'No precomputed mean, std avalaible for input_size = {input_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(input_size), transforms.ToTensor(), transforms.Normalize(pop_mean, pop_std0)])\n",
    "\n",
    "ds_train = tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/train', transform=transform)\n",
    "ds_val = tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/val', transform=transform)\n",
    "ds_test = tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/test', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = {}\n",
    "for k,v in ds_train.class_to_idx.items():\n",
    "    class_to_idx[k] = v\n",
    "class_to_idx = OrderedDict(sorted(class_to_idx.items(), key=lambda x: x))\n",
    "idx_to_class = OrderedDict([[v,k] for k,v in class_to_idx.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "dl_val = torch.utils.data.DataLoader(ds_val, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_train_results = train_model(dl_train, dl_val,\n",
    "model, optimizer, loss_fn, device,\n",
    "model_name=model_name, models_path=models_path,\n",
    "max_epochs=100,\n",
    "do_es=True, es_min_val_per_improvement=0.0005, es_epochs=10,\n",
    "do_decay_lr=False, # initial_lr=0.001, lr_epoch_period=25, lr_n_period_cap=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dfp(dfp_train_results, output_path , 'train_results', tag='',\n",
    "target_fixed_cols=['epoch', 'train_loss', 'val_loss', 'best_val_loss', 'delta_per_best', 'saved_model', 'elapsed_time', 'epoch_time', 'cuda_mem_alloc'],\n",
    "sort_by=['epoch'], sort_by_ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_train_results = load_dfp(output_path, 'train_results', tag='', cols_bool=['saved_model'],\n",
    "                             cols_float=['train_loss','val_loss','best_val_loss','delta_per_best','elapsed_time','epoch_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_vs_epoch(dfp_train_results, output_path, fname='loss_vs_epoch', tag='', inline=True,\n",
    "                   ann_text_std_add=None,\n",
    "                   y_axis_params={'log': True},\n",
    "                   loss_cols=['train_loss', 'val_loss'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = dfp_train_results.iloc[dfp_train_results['val_loss'].idxmin()]['epoch']\n",
    "load_model(model, device, best_epoch, model_name, models_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dl, device):\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    model.eval()\n",
    "    for (inputs, labels) in dl:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "\n",
    "    return all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, preds = eval_model(model, dl_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title=\"CM\"):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    #Plot matrix\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    #Format number color according to threshold\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    #Add labels\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(conf_matrix, classes=idx_to_class.values(), title='Confusion matrix, without normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_code import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
