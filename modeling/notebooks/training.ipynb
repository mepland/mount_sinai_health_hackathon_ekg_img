{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "For reference see [Finetuning Torchvision Models](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html)  \n",
    "For additional pretrained models see [rwightman/pytorch-image-models](https://github.com/rwightman/pytorch-image-models), in particular the [README model list](https://github.com/rwightman/pytorch-image-models#ported-weights), [EfficientNet generator](https://github.com/rwightman/gen-efficientnet-pytorch/blob/master/geffnet/gen_efficientnet.py), and [pretrained weights](https://github.com/rwightman/pytorch-image-models/releases/tag/v0.1-weights)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys\n",
    "get_ipython().system('{sys.executable} -m pip install --upgrade pip');\n",
    "get_ipython().system('{sys.executable} -m pip install -r ../requirements.txt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "sys.path.append(os.path.expanduser('~/mount_sinai_health_hackathon_ekg_img/'))\n",
    "from common_code import *\n",
    "%matplotlib inline\n",
    "\n",
    "import timm # pretrained models from rwightman/pytorch-image-models\n",
    "import torchvision.models as models # pretrained models from pytorch\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if gpu support is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dx_classes = {\n",
    "'Normal': 'Normal sinus rhythm',\n",
    "'AF': 'Atrial fibrillation',\n",
    "'I-AVB': 'Airst-degree atrioventricular block',\n",
    "'LBBB': 'Left bundle branch block',\n",
    "'PAC': 'Premature atrial complex',\n",
    "'PVC': 'Premature ventricular complex',\n",
    "'RBBB': 'Right bundle branch block',\n",
    "'STD': 'ST-segment depression',\n",
    "'STE': 'ST-segment elevation',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to choose from [tf_efficientnet_b7_ns, tf_efficientnet_b6_ns, resnet, alexnet, vgg, squeezenet, densenet] # inception\n",
    "model_name = 'tf_efficientnet_b7_ns' # 600\n",
    "# model_name = 'tf_efficientnet_b6_ns' # 528\n",
    "# model_name = 'resnet' # 224\n",
    "\n",
    "# resume training on a prior model\n",
    "resume_training = True\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have, and how large the model is)\n",
    "batch_size = 40 # 32 was working with 2.8 GB memory left, 40 works with around 1 GB. 45 didn't work. These images are only a few kb so I'm not sure what's driving that scaling...\n",
    "\n",
    "# Flag for feature extraction. When True only update the reshaped layer params, when False train the whole model from scratch. Should probably remain True.\n",
    "feature_extract = True\n",
    "\n",
    "# use pretrained model, should probably remain True.\n",
    "use_pretrained=True\n",
    "\n",
    "# Number of classes in the dataset\n",
    "n_classes = len(Dx_classes.keys())\n",
    "\n",
    "# path to data dir\n",
    "data_path = os.path.expanduser('~/mount_sinai_health_hackathon_ekg_img/data')\n",
    "\n",
    "# resolution of preprocessed images\n",
    "im_res = 600\n",
    "# im_res=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'../output/{model_name}'\n",
    "models_path = f'../models/{model_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Make Training Deterministic\n",
    "See [Pytorch's Docs on Reproducibility](https://pytorch.org/docs/stable/notes/randomness.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_seed=42\n",
    "np.random.seed(rnd_seed)\n",
    "torch.manual_seed(rnd_seed+1)\n",
    "if str(device) == 'cuda':\n",
    "    torch.cuda.manual_seed(rnd_seed+2)\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathers the parameters to be optimized/updated in training. If we are finetuning we will be updating all parameters\n",
    "# However, if we are using the feature extract method, we will only update the parameters that we have just initialized,\n",
    "# i.e. the parameters with requires_grad is True.\n",
    "\n",
    "def get_parameter_requires_grad(model, feature_extracting, print_not_feature_extracting=False):\n",
    "    params_to_update = model.parameters()\n",
    "    if feature_extracting:\n",
    "        print('Params to learn:')\n",
    "        params_to_update = []\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(name)\n",
    "    else:\n",
    "        if print_not_feature_extracting:\n",
    "            print('Params to learn:')\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                if print_not_feature_extracting:\n",
    "                    print(name)\n",
    "    return params_to_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, n_classes, feature_extract, use_pretrained=True):\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == 'tf_efficientnet_b7_ns':\n",
    "        ''' EfficientNet-B7 NoisyStudent. Tensorflow compatible variant\n",
    "            Paper: Self-training with Noisy Student improves ImageNet classification (https://arxiv.org/abs/1911.04252)\n",
    "        '''\n",
    "        model_ft = timm.create_model('tf_efficientnet_b7_ns', pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = model_ft.default_cfg['input_size'][1]\n",
    "\n",
    "    elif model_name == 'tf_efficientnet_b6_ns':\n",
    "        ''' EfficientNet-B6 NoisyStudent. Tensorflow compatible variant\n",
    "            Paper: Self-training with Noisy Student improves ImageNet classification (https://arxiv.org/abs/1911.04252)\n",
    "        '''\n",
    "        model_ft = timm.create_model('tf_efficientnet_b6_ns', pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = model_ft.default_cfg['input_size'][1]\n",
    "\n",
    "    elif model_name == 'resnet':\n",
    "        ''' Resnet101\n",
    "        '''\n",
    "        model_ft = models.resnet101(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'alexnet':\n",
    "        ''' Alexnet\n",
    "        '''\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,n_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'vgg':\n",
    "        ''' VGG11_bn\n",
    "        '''\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,n_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'squeezenet':\n",
    "        ''' Squeezenet\n",
    "        '''\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, n_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.n_classes = n_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'densenet':\n",
    "        ''' Densenet\n",
    "        '''\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = 224\n",
    "\n",
    "#    elif model_name == 'inception':\n",
    "#        ''' Inception v3\n",
    "#        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "#        '''\n",
    "#        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "#        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "#        # Handle the auxilary net\n",
    "#        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "#        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, n_classes)\n",
    "#        # Handle the primary net\n",
    "#        num_ftrs = model_ft.fc.in_features\n",
    "#        model_ft.fc = nn.Linear(num_ftrs,n_classes)\n",
    "#        input_size = 299\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'Invalid model_name = {model_name}')\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, input_size = initialize_model(model_name, n_classes, feature_extract, use_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size = 600\n"
     ]
    }
   ],
   "source": [
    "print(f'input_size = {input_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if im_res < input_size:\n",
    "    raise ValueError(f'Warning, trying to run a model with an input size of {input_size}x{input_size} on images that are only {im_res}x{im_res}! You can proceed at your own risk, ie upscaling, better to fix one or the other size though!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/nn.html#crossentropyloss\n",
    "loss_fn = nn.CrossEntropyLoss(weight=None, reduction='mean')\n",
    "# TODo if we move to unbalanced classes / full dataset, add weights to correct\n",
    "# reduction='mean', return mean CrossEntropyLoss over batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "classifier.weight\n",
      "classifier.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = get_parameter_requires_grad(model, feature_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer\n",
    "optimizer = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(params_to_update, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Load Previously Trained Model\n",
    "To continue the training in another session  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming Training!\n"
     ]
    }
   ],
   "source": [
    "if resume_training:\n",
    "    print('Resuming Training!')\n",
    "    dfp_train_results_prior = load_dfp(models_path, 'train_results', tag='', cols_bool=['saved_model'],\n",
    "                                       cols_float=['train_loss','val_loss','best_val_loss','delta_per_best','elapsed_time','epoch_time'])\n",
    "\n",
    "    best_epoch = dfp_train_results_prior.iloc[dfp_train_results_prior['val_loss'].idxmin()]['epoch']\n",
    "    load_model(model, device, best_epoch, model_name, models_path)\n",
    "else:\n",
    "    dfp_train_results_prior = None\n",
    "    model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Normalization Factors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dl_unnormalized = torch.utils.data.DataLoader(\n",
    "    tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/train',\n",
    "                            transform=transforms.Compose([transforms.Grayscale(num_output_channels=3), transforms.Resize(input_size), transforms.ToTensor()])),\n",
    "    batch_size=batch_size, shuffle=False, num_workers=8\n",
    ")\n",
    "\n",
    "pop_mean, pop_std0 = compute_channel_norms(dl_unnormalized)\n",
    "\n",
    "print(f\"pop_mean = [{', '.join([f'{v:.8f}' for v in pop_mean])}]\")\n",
    "print(f\"pop_std0 = [{', '.join([f'{v:.8f}' for v in pop_std0])}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use normalization results computed earlier\n",
    "if input_size == 224:\n",
    "    pop_mean = np.array([])\n",
    "    pop_std0 = np.array([])\n",
    "elif input_size == 600:\n",
    "    pop_mean = np.array([0.95724732, 0.95724732, 0.95724732])\n",
    "    pop_std0 = np.array([0.08290727, 0.08290727, 0.08290727])\n",
    "elif input_size == 800:\n",
    "    pop_mean = np.array([])\n",
    "    pop_std0 = np.array([])\n",
    "else:\n",
    "    raise ValueError(f'No precomputed mean, std available for input_size = {input_size}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# use normalization results used when training the model, only works for timm models. Should probably only use for color images\n",
    "pop_mean = np.array(model.default_cfg['mean'])\n",
    "pop_std0 = np.array(model.default_cfg['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop_mean = [0.95724732, 0.95724732, 0.95724732]\n",
      "pop_std0 = [0.08290727, 0.08290727, 0.08290727]\n"
     ]
    }
   ],
   "source": [
    "print(f\"pop_mean = [{', '.join([f'{v:.8f}' for v in pop_mean])}]\")\n",
    "print(f\"pop_std0 = [{', '.join([f'{v:.8f}' for v in pop_std0])}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to fake 3 channels r = b = g with Grayscale to use pretrained networks\n",
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=3), transforms.Resize(input_size), transforms.ToTensor(), transforms.Normalize(pop_mean, pop_std0)])\n",
    "\n",
    "ds_train = tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/train', transform=transform)\n",
    "ds_val = tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/val', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = {}\n",
    "for k,v in ds_train.class_to_idx.items():\n",
    "    class_to_idx[k] = v\n",
    "class_to_idx = OrderedDict(sorted(class_to_idx.items(), key=lambda x: x))\n",
    "idx_to_class = OrderedDict([[v,k] for k,v in class_to_idx.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=8)\n",
    "dl_val = torch.utils.data.DataLoader(ds_val, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_test = tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/test', transform=transform)\n",
    "# dl_test = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, pin_memory=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d75a00d8f724a7b999af8efeaca91e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=300.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   70, Train Loss: 5.580975540, Val Loss: 1.481345859, Delta Best:  -0.064%, Model Saved!\n",
      "Epoch:   71, Train Loss: 1.350986471, Val Loss: 1.477746955, Delta Best:  -0.243%, Model Saved!\n",
      "Epoch:   72, Train Loss: 4491.236773811, Val Loss: 1.477359574, Delta Best:  -0.026%, Model Saved!\n"
     ]
    }
   ],
   "source": [
    "dfp_train_results = train_model(dl_train, dl_val,\n",
    "model, optimizer, loss_fn, device,\n",
    "model_name=model_name, models_path=models_path,\n",
    "max_epochs=300, max_time_min=900,\n",
    "do_es=True, es_min_val_per_improvement=0.0005, es_epochs=10,\n",
    "do_decay_lr=False, # initial_lr=0.001, lr_epoch_period=25, lr_n_period_cap=4,\n",
    "save_model_inhibit=10, # don't save anything out for the first save_model_inhibit epochs, set to -1 to start saving immediately\n",
    "n_models_on_disk=3, # keep the last n_models_on_disk models on disk, set to -1 to keep all\n",
    "dfp_train_results_prior=dfp_train_results_prior # dfp_train_results from prior training session, use to resume\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_train_results = load_dfp(models_path, 'train_results', tag='', cols_bool=['saved_model'],\n",
    "                             cols_float=['train_loss','val_loss','best_val_loss','delta_per_best','elapsed_time','epoch_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_vs_epoch(dfp_train_results, output_path, fname='loss_vs_epoch', tag='_val', inline=False,\n",
    "                   ann_text_std_add=None,\n",
    "                   y_axis_params={'log': False},\n",
    "                   loss_cols=['val_loss'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_vs_epoch(dfp_train_results, output_path, fname='loss_vs_epoch', tag='_train', inline=False,\n",
    "                   ann_text_std_add=None,\n",
    "                   y_axis_params={'log': False},\n",
    "                   loss_cols=['train_loss'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_loss_vs_epoch(dfp_train_results, output_path, fname='loss_vs_epoch', tag='', inline=True,\n",
    "                   ann_text_std_add=None,\n",
    "                   y_axis_params={'log': False},\n",
    "                   loss_cols=['train_loss', 'val_loss'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = dfp_train_results.iloc[dfp_train_results['val_loss'].idxmin()]['epoch']\n",
    "load_model(model, device, best_epoch, model_name, models_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, preds = get_preds(dl_val, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true=labels, y_pred=preds, labels=[class_to_idx[k] for k in Dx_classes.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = {'_val': True, '_raw_val': False}\n",
    "for tag,norm in cms.items():\n",
    "    plot_confusion_matrix(conf_matrix, label_names=Dx_classes.keys(),\n",
    "                          m_path=output_path, tag=tag, inline=False,\n",
    "                          ann_text_std_add=None,\n",
    "                          normalize=norm,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_code import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
