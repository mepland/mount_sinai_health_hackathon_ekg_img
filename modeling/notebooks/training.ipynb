{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "For reference see [Finetuning Torchvision Models](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html)  \n",
    "For additional pretrained models see [rwightman/pytorch-image-models](https://github.com/rwightman/pytorch-image-models), in particular the [README model list](https://github.com/rwightman/pytorch-image-models#ported-weights), [EfficientNet generator](https://github.com/rwightman/gen-efficientnet-pytorch/blob/master/geffnet/gen_efficientnet.py), and [pretrained weights](https://github.com/rwightman/pytorch-image-models/releases/tag/v0.1-weights)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys\n",
    "get_ipython().system('{sys.executable} -m pip install --upgrade pip');\n",
    "get_ipython().system('{sys.executable} -m pip install -r ../requirements.txt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "sys.path.append(os.path.expanduser('~/mount_sinai_health_hackathon_ekg_img/'))\n",
    "sys.path.append(os.path.expanduser('~/mount_sinai_health_hackathon_ekg_img/modeling'))\n",
    "from common_code import *\n",
    "%matplotlib inline\n",
    "\n",
    "import timm # pretrained models from rwightman/pytorch-image-models\n",
    "import torchvision.models as models # pretrained models from pytorch\n",
    "from mobilenetv3 import MobileNetV3 # mobilenetv3 definition\n",
    "\n",
    "from torchsummary import summary, summary_string\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if gpu support is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dx_classes = {\n",
    "'Normal': 'Normal sinus rhythm',\n",
    "'AF': 'Atrial fibrillation',\n",
    "'I-AVB': 'First-degree atrioventricular block',\n",
    "'LBBB': 'Left bundle branch block',\n",
    "# 'PAC': 'Premature atrial complex',\n",
    "# 'PVC': 'Premature ventricular complex',\n",
    "'RBBB': 'Right bundle branch block',\n",
    "'STD': 'ST-segment depression',\n",
    "'STE': 'ST-segment elevation',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to choose from [mobilenetv3_small_custom, tf_efficientnet_b7_ns, tf_efficientnet_b6_ns, resnet, alexnet, vgg, squeezenet, densenet]\n",
    "\n",
    "model_name = 'mobilenetv3_small_custom' # Any dimension, tested at 600 and 800\n",
    "# model_name = 'tf_efficientnet_b7_ns' # 600\n",
    "# model_name = 'tf_efficientnet_b6_ns' # 528\n",
    "# model_name = 'resnet' # 224\n",
    "\n",
    "# resume training on a prior model\n",
    "resume_training = False\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have, and how large the model is)\n",
    "batch_size = 32 # 40\n",
    "\n",
    "# balance classes by reweighting in loss function\n",
    "balance_class_weights = True\n",
    "\n",
    "# use pretrained model, should probably remain True.\n",
    "use_pretrained=False # True\n",
    "\n",
    "# Flag for feature extraction. When True only update the reshaped layer params, when False train the whole model from scratch. Should probably remain True.\n",
    "feature_extract = False\n",
    "\n",
    "# Number of classes in the dataset\n",
    "n_classes = len(Dx_classes.keys())\n",
    "\n",
    "# path to data dir\n",
    "data_path = os.path.expanduser('~/mount_sinai_health_hackathon_ekg_img/data')\n",
    "\n",
    "# channels of preprocessed images to use, 1 or 3\n",
    "im_channels=1\n",
    "\n",
    "# resolution of preprocessed images\n",
    "im_res = 800\n",
    "# im_res = 600\n",
    "\n",
    "# training settings\n",
    "do_es=True\n",
    "es_min_val_per_improvement=0.0005\n",
    "es_epochs=10\n",
    "do_decay_lr=False\n",
    "# initial_lr=0.001\n",
    "# lr_epoch_period=25\n",
    "# lr_n_period_cap=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '_custom' in model_name:\n",
    "    if use_pretrained:\n",
    "        raise ValueError('Can not use a pretrained custom model!')\n",
    "    if feature_extract and not use_pretrained:\n",
    "        raise ValueError('Can not update last feature layer for a non pretrained model!')\n",
    "else:\n",
    "    if im_channels != 3:\n",
    "        raise ValueError('Must have 3 initial color channels for most standard models!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'../output/{model_name}'\n",
    "models_path = f'../models/{model_name}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Make Training Deterministic\n",
    "See [Pytorch's Docs on Reproducibility](https://pytorch.org/docs/stable/notes/randomness.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_seed=44\n",
    "np.random.seed(rnd_seed)\n",
    "torch.manual_seed(rnd_seed+1)\n",
    "if str(device) == 'cuda':\n",
    "    torch.cuda.manual_seed(rnd_seed+2)\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathers the parameters to be optimized/updated in training. If we are finetuning we will be updating all parameters\n",
    "# However, if we are using the feature extract method, we will only update the parameters that we have just initialized,\n",
    "# i.e. the parameters with requires_grad is True.\n",
    "\n",
    "def get_parameter_requires_grad(model, feature_extracting, print_not_feature_extracting=False):\n",
    "    params_to_update = model.parameters()\n",
    "    if feature_extracting:\n",
    "        print('Params to learn:')\n",
    "        params_to_update = []\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(name)\n",
    "    else:\n",
    "        if print_not_feature_extracting:\n",
    "            print('Params to learn:')\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                if print_not_feature_extracting:\n",
    "                    print(name)\n",
    "    return params_to_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenetv3_small_custom(cfgs=None, **kwargs):\n",
    "    if cfgs is None:\n",
    "        # use original cfgs for mobilentv3 small\n",
    "         cfgs = [\n",
    "            # k, t, c, SE, HS, s\n",
    "            [3,    1,  16, 1, 0, 2],\n",
    "            [3,  4.5,  24, 0, 0, 2],\n",
    "            [3, 3.67,  24, 0, 0, 1],\n",
    "            [5,    4,  40, 1, 1, 2],\n",
    "            [5,    6,  40, 1, 1, 1],\n",
    "            [5,    6,  40, 1, 1, 1],\n",
    "            [5,    3,  48, 1, 1, 1],\n",
    "            [5,    3,  48, 1, 1, 1],\n",
    "            [5,    6,  96, 1, 1, 2],\n",
    "            [5,    6,  96, 1, 1, 1],\n",
    "            [5,    6,  96, 1, 1, 1],\n",
    "        ]\n",
    "    return MobileNetV3(cfgs, mode='small', **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, n_classes, feature_extract, use_pretrained=True):\n",
    "    model = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == 'mobilenetv3_small_custom':\n",
    "        ''' (Modified) MobileNetV3 Small\n",
    "            Paper: Searching for MobileNetV3 (https://arxiv.org/abs/1905.02244)\n",
    "        '''\n",
    "        cfgs = [\n",
    "            # k, t, c, SE, HS, s\n",
    "            [3,    1,  4, 1, 0, 2],\n",
    "            [3,  4.5,  8, 0, 0, 2],\n",
    "            [3, 3.67,  8, 0, 0, 1],\n",
    "            [5,    4,  16, 1, 1, 2],\n",
    "            [5,    6,  16, 1, 1, 1],\n",
    "            [5,    6,  30, 1, 1, 1],\n",
    "            [5,    3,  30, 1, 1, 1],\n",
    "        ]\n",
    "        model = mobilenetv3_small_custom(cfgs, num_classes=n_classes, im_channels=im_channels)\n",
    "        input_size = im_res\n",
    "    elif model_name == 'tf_efficientnet_b7_ns':\n",
    "        ''' EfficientNet-B7 NoisyStudent. Tensorflow compatible variant\n",
    "            Paper: Self-training with Noisy Student improves ImageNet classification (https://arxiv.org/abs/1911.04252)\n",
    "        '''\n",
    "        model = timm.create_model('tf_efficientnet_b7_ns', pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = model.default_cfg['input_size'][1]\n",
    "    elif model_name == 'tf_efficientnet_b6_ns':\n",
    "        ''' EfficientNet-B6 NoisyStudent. Tensorflow compatible variant\n",
    "            Paper: Self-training with Noisy Student improves ImageNet classification (https://arxiv.org/abs/1911.04252)\n",
    "        '''\n",
    "        model = timm.create_model('tf_efficientnet_b6_ns', pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = model.default_cfg['input_size'][1]\n",
    "    elif model_name == 'resnet':\n",
    "        ''' Resnet101\n",
    "        '''\n",
    "        model = models.resnet101(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == 'alexnet':\n",
    "        ''' Alexnet\n",
    "        '''\n",
    "        model = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_ftrs,n_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == 'vgg':\n",
    "        ''' VGG11_bn\n",
    "        '''\n",
    "        model = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_ftrs,n_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == 'squeezenet':\n",
    "        ''' Squeezenet\n",
    "        '''\n",
    "        model = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        model.classifier[1] = nn.Conv2d(512, n_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model.n_classes = n_classes\n",
    "        input_size = 224\n",
    "    elif model_name == 'densenet':\n",
    "        ''' Densenet\n",
    "        '''\n",
    "        model = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model, feature_extract)\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "        input_size = 224\n",
    "    else:\n",
    "        raise ValueError(f'Invalid model_name = {model_name}')\n",
    "\n",
    "    return model, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, input_size = initialize_model(model_name, n_classes, feature_extract, use_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size = 800\n"
     ]
    }
   ],
   "source": [
    "print(f'input_size = {input_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if im_res < input_size:\n",
    "    raise ValueError(f'Warning, trying to run a model with an input size of {input_size}x{input_size} on images that are only {im_res}x{im_res}! You can proceed at your own risk, ie upscaling, better to fix one or the other size though!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = get_parameter_requires_grad(model, feature_extract, print_not_feature_extracting=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer\n",
    "optimizer = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(params_to_update, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Load Previously Trained Model\n",
    "To continue the training in another session  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume_training:\n",
    "    print('Resuming Training!')\n",
    "    dfp_train_results_prior = load_dfp(models_path, 'train_results', tag='', cols_bool=['saved_model'],\n",
    "                                       cols_float=['train_loss','val_loss','best_val_loss','delta_per_best','elapsed_time','epoch_time'])\n",
    "\n",
    "    best_epoch = dfp_train_results_prior.iloc[dfp_train_results_prior['val_loss'].idxmin()]['epoch']\n",
    "    load_model(model, device, best_epoch, model_name, models_path)\n",
    "else:\n",
    "    dfp_train_results_prior = None\n",
    "    model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Normalization Factors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dl_unnormalized = torch.utils.data.DataLoader(\n",
    "    tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/train',\n",
    "                            transform=transforms.Compose([transforms.Grayscale(num_output_channels=3), transforms.Resize(input_size), transforms.ToTensor()])),\n",
    "    batch_size=batch_size, shuffle=False, num_workers=8\n",
    ")\n",
    "\n",
    "norm_mean, norm_std0 = compute_channel_norms(dl_unnormalized)\n",
    "\n",
    "print(f\"norm_mean = [{', '.join([f'{v:.8f}' for v in norm_mean])}]\")\n",
    "print(f\"norm_std0 = [{', '.join([f'{v:.8f}' for v in norm_std0])}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use normalization results computed earlier\n",
    "if input_size == 224:\n",
    "    norm_mean = np.array([])\n",
    "    norm_std0 = np.array([])\n",
    "elif input_size == 600:\n",
    "    norm_mean = np.array([])\n",
    "    norm_std0 = np.array([])\n",
    "elif input_size == 800:\n",
    "    norm_mean = np.array([0.95816243, 0.95816243, 0.95816243])\n",
    "    norm_std0 = np.array([0.09317242, 0.09317242, 0.09317242])\n",
    "else:\n",
    "    raise ValueError(f'No precomputed mean, std available for input_size = {input_size}')\n",
    "\n",
    "if im_channels == 1:\n",
    "    norm_mean = np.array([norm_mean[0]])\n",
    "    norm_std0 = np.array([norm_std0[0]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# use normalization results used when training the model, only works for timm models. Should probably only use for color images\n",
    "norm_mean = np.array(model.default_cfg['mean'])\n",
    "norm_std0 = np.array(model.default_cfg['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_mean = [0.95816243]\n",
      "norm_std0 = [0.09317242]\n"
     ]
    }
   ],
   "source": [
    "print(f\"norm_mean = [{', '.join([f'{v:.8f}' for v in norm_mean])}]\")\n",
    "print(f\"norm_std0 = [{', '.join([f'{v:.8f}' for v in norm_std0])}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to fake 3 channels r = b = g with Grayscale to use pretrained networks\n",
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=im_channels), transforms.Resize(input_size), transforms.ToTensor(), transforms.Normalize(norm_mean, norm_std0)])\n",
    "\n",
    "ds_train = tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/train', transform=transform)\n",
    "ds_val = tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/val', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = {}\n",
    "for k,v in ds_train.class_to_idx.items():\n",
    "    class_to_idx[k] = v\n",
    "class_to_idx = dict(sorted(class_to_idx.items(), key=lambda x: x))\n",
    "idx_to_class = dict([[v,k] for k,v in class_to_idx.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_memory=True\n",
    "\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, pin_memory=pin_memory, num_workers=8)\n",
    "dl_val = torch.utils.data.DataLoader(ds_val, batch_size=batch_size, shuffle=True, pin_memory=pin_memory, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = tv.datasets.ImageFolder(root=f'{data_path}/preprocessed/im_res_{im_res}/test', transform=transform)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, pin_memory=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Setup Loss Function\n",
    "Balance class weights or leave with None, ie uniform, weights  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _count_and_weight(ds, verbose=True):\n",
    "    class_counts = torch.zeros(n_classes)\n",
    "\n",
    "    for idx in range(n_classes):\n",
    "        idx_class_tensor = torch.tensor(ds.targets) == idx\n",
    "        class_counts[idx] = idx_class_tensor.sum().item()\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Class Counts: {class_counts}')\n",
    "\n",
    "    if balance_class_weights:\n",
    "        class_weights = class_counts.sum() / class_counts\n",
    "        class_weights = class_weights / class_weights.max()\n",
    "        class_weights = class_weights.to(device)\n",
    "        if verbose:\n",
    "            print(f'Class Weights: {class_weights}')\n",
    "\n",
    "            class_counts_weighted = class_counts\n",
    "            for i in range(len(class_counts)):\n",
    "                class_counts_weighted[i] = class_weights[i]*class_counts_weighted[i]\n",
    "            print(f'Class Counts Weighted: {class_counts_weighted}')\n",
    "    else:\n",
    "        class_weights=None\n",
    "        if verbose:\n",
    "            print('Using default, ie uniform, weights')\n",
    "\n",
    "    return class_counts, class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts: tensor([2946., 1958.,  523., 2846., 4411., 2320.,  608.])\n",
      "Class Weights: tensor([0.1775, 0.2671, 1.0000, 0.1838, 0.1186, 0.2254, 0.8602],\n",
      "       device='cuda:0')\n",
      "Class Counts Weighted: tensor([523.0000, 522.9999, 523.0000, 523.0000, 523.0000, 523.0000, 523.0000])\n"
     ]
    }
   ],
   "source": [
    "class_counts_train, class_weights_train = _count_and_weight(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts: tensor([601., 416.,  93., 620., 929., 481., 131.])\n",
      "Class Weights: tensor([0.1547, 0.2236, 1.0000, 0.1500, 0.1001, 0.1933, 0.7099],\n",
      "       device='cuda:0')\n",
      "Class Counts Weighted: tensor([93.0000, 93.0000, 93.0000, 93.0000, 93.0000, 93.0000, 93.0000])\n"
     ]
    }
   ],
   "source": [
    "class_counts_val, class_weights_val = _count_and_weight(ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts: tensor([625., 403., 120., 619., 928., 496., 120.])\n",
      "Class Weights: tensor([0.1920, 0.2978, 1.0000, 0.1939, 0.1293, 0.2419, 1.0000],\n",
      "       device='cuda:0')\n",
      "Class Counts Weighted: tensor([120.0000, 120.0000, 120.0000, 120.0000, 120.0000, 120.0000, 120.0000])\n"
     ]
    }
   ],
   "source": [
    "class_counts_test, class_weights_test = _count_and_weight(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/nn.html#crossentropyloss\n",
    "reduction='mean' # return mean CrossEntropyLoss over batches\n",
    "loss_fn_train = nn.CrossEntropyLoss(weight=class_weights_train, reduction=reduction)\n",
    "loss_fn_val = nn.CrossEntropyLoss(weight=class_weights_val, reduction=reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs=300\n",
    "max_time_min=180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_str, (total_params, trainable_params) = summary_string(model, (1, input_size, input_size), batch_size=batch_size, device=device)\n",
    "model_eval_str = str(model.eval)\n",
    "\n",
    "model_info = {\n",
    "    'start_time': str(dt.datetime.now()),\n",
    "    'model_name': model_name,\n",
    "    'total_params': total_params.item(),\n",
    "    'trainable_params': trainable_params.item(),\n",
    "    'optimizer': str(optimizer).replace('\\n   ', ',').replace('\\n', ''),\n",
    "    'loss_fn': str(loss_fn_train),\n",
    "    'loss_fn.reduction': loss_fn_train.reduction,\n",
    "    'max_epochs': max_epochs,\n",
    "    'max_time_min': max_time_min,\n",
    "    'do_es': do_es,\n",
    "    'es_min_val_per_improvement': es_min_val_per_improvement,\n",
    "    'es_epochs': es_epochs,\n",
    "    'do_decay_lr': do_decay_lr,\n",
    "    'resume_training': resume_training,\n",
    "    'batch_size': batch_size,\n",
    "    'feature_extract': feature_extract,\n",
    "    'use_pretrained': use_pretrained,\n",
    "    'balance_class_weights': balance_class_weights,\n",
    "    'class_counts_train': ', '.join([f'{c:.0f}' for c in class_counts_train]),\n",
    "    'class_weights_train': ', '.join([f'{c:f}' for c in class_weights_train]),\n",
    "    'class_counts_val': ', '.join([f'{c:.0f}' for c in class_counts_val]),\n",
    "    'class_weights_val': ', '.join([f'{c:f}' for c in class_weights_val]),\n",
    "    'class_counts_test': ', '.join([f'{c:.0f}' for c in class_counts_test]),\n",
    "    'class_weights_test': ', '.join([f'{c:f}' for c in class_weights_test]),\n",
    "    'data_path': data_path,\n",
    "    'input_size': input_size,\n",
    "    'im_res': im_res,\n",
    "    'im_channels': im_channels,\n",
    "    'rnd_seed': rnd_seed,\n",
    "    'norm_mean': ', '.join([f'{c:f}' for c in norm_mean]),\n",
    "    'norm_std0': ', '.join([f'{c:f}' for c in norm_std0]),\n",
    "    'starting_memory': f'CUDA memory allocated: {humanize.naturalsize(torch.cuda.memory_allocated())}, cached: {humanize.naturalsize(torch.cuda.memory_cached())}',\n",
    "    'pin_memory': pin_memory,\n",
    "    'n_classes': n_classes,\n",
    "    'idx_to_class': idx_to_class,\n",
    "    'Dx_classes': Dx_classes,\n",
    "}\n",
    "\n",
    "os.makedirs(models_path, exist_ok=True)\n",
    "with open(os.path.join(models_path, 'model_info.json'), 'w') as f_json:\n",
    "    json.dump(model_info, f_json, sort_keys=False, indent=4)\n",
    "\n",
    "with open(os.path.join(models_path, 'model_summary.txt'), 'w') as f:\n",
    "    f.write(summary_str)\n",
    "    f.close()\n",
    "\n",
    "with open(os.path.join(models_path, 'model_eval.txt'), 'w') as f:\n",
    "    f.write(model_eval_str)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_train_results = train_model(dl_train, dl_val,\n",
    "model, optimizer, loss_fn_train, loss_fn_val, device,\n",
    "model_name=model_name, models_path=models_path,\n",
    "max_epochs=max_epochs, max_time_min=max_time_min,\n",
    "do_es=do_es, es_min_val_per_improvement=es_min_val_per_improvement, es_epochs=es_epochs,\n",
    "do_decay_lr=do_decay_lr, # initial_lr=0.001, lr_epoch_period=25, lr_n_period_cap=4,\n",
    "# save_model_inhibit=10, # don't save anything out for the first save_model_inhibit epochs, set to -1 to start saving immediately\n",
    "n_models_on_disk=3, # keep the last n_models_on_disk models on disk, set to -1 to keep all\n",
    "dfp_train_results_prior=dfp_train_results_prior # dfp_train_results from prior training session, use to resume\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_train_results = load_dfp(models_path, 'train_results', tag='', cols_bool=['saved_model'],\n",
    "                             cols_float=['train_loss','val_loss','best_val_loss','delta_per_best','elapsed_time','epoch_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>best_val_loss</th>\n",
       "      <th>delta_per_best</th>\n",
       "      <th>saved_model</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>epoch_time</th>\n",
       "      <th>cuda_mem_alloc</th>\n",
       "      <th>cuda_mem_cached</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.944045</td>\n",
       "      <td>1.944432</td>\n",
       "      <td>1.944432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.719959</td>\n",
       "      <td>1.719750</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.941513</td>\n",
       "      <td>1.942414</td>\n",
       "      <td>1.942414</td>\n",
       "      <td>-0.001038</td>\n",
       "      <td>True</td>\n",
       "      <td>3.416122</td>\n",
       "      <td>1.695755</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.935181</td>\n",
       "      <td>1.938070</td>\n",
       "      <td>1.938070</td>\n",
       "      <td>-0.002236</td>\n",
       "      <td>True</td>\n",
       "      <td>5.111468</td>\n",
       "      <td>1.695062</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.878736</td>\n",
       "      <td>1.896016</td>\n",
       "      <td>1.896016</td>\n",
       "      <td>-0.021699</td>\n",
       "      <td>True</td>\n",
       "      <td>6.805496</td>\n",
       "      <td>1.693736</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.709899</td>\n",
       "      <td>1.744386</td>\n",
       "      <td>1.744386</td>\n",
       "      <td>-0.079973</td>\n",
       "      <td>True</td>\n",
       "      <td>8.499399</td>\n",
       "      <td>1.693619</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.669752</td>\n",
       "      <td>1.699744</td>\n",
       "      <td>1.699744</td>\n",
       "      <td>-0.025592</td>\n",
       "      <td>True</td>\n",
       "      <td>10.189940</td>\n",
       "      <td>1.690258</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.648135</td>\n",
       "      <td>1.686584</td>\n",
       "      <td>1.686584</td>\n",
       "      <td>-0.007742</td>\n",
       "      <td>True</td>\n",
       "      <td>11.885094</td>\n",
       "      <td>1.694870</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.610812</td>\n",
       "      <td>1.645744</td>\n",
       "      <td>1.645744</td>\n",
       "      <td>-0.024215</td>\n",
       "      <td>True</td>\n",
       "      <td>13.575628</td>\n",
       "      <td>1.690241</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.568820</td>\n",
       "      <td>1.613060</td>\n",
       "      <td>1.613060</td>\n",
       "      <td>-0.019860</td>\n",
       "      <td>True</td>\n",
       "      <td>15.271691</td>\n",
       "      <td>1.695780</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.547423</td>\n",
       "      <td>1.586713</td>\n",
       "      <td>1.586713</td>\n",
       "      <td>-0.016333</td>\n",
       "      <td>True</td>\n",
       "      <td>16.971641</td>\n",
       "      <td>1.699658</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1.519211</td>\n",
       "      <td>1.552478</td>\n",
       "      <td>1.552478</td>\n",
       "      <td>-0.021576</td>\n",
       "      <td>True</td>\n",
       "      <td>18.665402</td>\n",
       "      <td>1.693469</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1.732850</td>\n",
       "      <td>1.775037</td>\n",
       "      <td>1.552478</td>\n",
       "      <td>0.143357</td>\n",
       "      <td>False</td>\n",
       "      <td>20.358454</td>\n",
       "      <td>1.692769</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1.476497</td>\n",
       "      <td>1.527909</td>\n",
       "      <td>1.527909</td>\n",
       "      <td>-0.015826</td>\n",
       "      <td>True</td>\n",
       "      <td>22.045985</td>\n",
       "      <td>1.687447</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1.473043</td>\n",
       "      <td>1.548228</td>\n",
       "      <td>1.527909</td>\n",
       "      <td>0.013299</td>\n",
       "      <td>False</td>\n",
       "      <td>23.746710</td>\n",
       "      <td>1.700442</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1.651360</td>\n",
       "      <td>1.678878</td>\n",
       "      <td>1.527909</td>\n",
       "      <td>0.098807</td>\n",
       "      <td>False</td>\n",
       "      <td>25.442898</td>\n",
       "      <td>1.696096</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1.352985</td>\n",
       "      <td>1.424677</td>\n",
       "      <td>1.424677</td>\n",
       "      <td>-0.067564</td>\n",
       "      <td>True</td>\n",
       "      <td>27.141163</td>\n",
       "      <td>1.698182</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1.678987</td>\n",
       "      <td>1.718448</td>\n",
       "      <td>1.424677</td>\n",
       "      <td>0.206202</td>\n",
       "      <td>False</td>\n",
       "      <td>28.835183</td>\n",
       "      <td>1.693728</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1.291691</td>\n",
       "      <td>1.377351</td>\n",
       "      <td>1.377351</td>\n",
       "      <td>-0.033219</td>\n",
       "      <td>True</td>\n",
       "      <td>30.528552</td>\n",
       "      <td>1.693286</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1.211967</td>\n",
       "      <td>1.306961</td>\n",
       "      <td>1.306961</td>\n",
       "      <td>-0.051105</td>\n",
       "      <td>True</td>\n",
       "      <td>32.220704</td>\n",
       "      <td>1.691868</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1.134376</td>\n",
       "      <td>1.225562</td>\n",
       "      <td>1.225562</td>\n",
       "      <td>-0.062281</td>\n",
       "      <td>True</td>\n",
       "      <td>33.911296</td>\n",
       "      <td>1.690300</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1.048499</td>\n",
       "      <td>1.170474</td>\n",
       "      <td>1.170474</td>\n",
       "      <td>-0.044949</td>\n",
       "      <td>True</td>\n",
       "      <td>35.619127</td>\n",
       "      <td>1.707531</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1.001748</td>\n",
       "      <td>1.116466</td>\n",
       "      <td>1.116466</td>\n",
       "      <td>-0.046142</td>\n",
       "      <td>True</td>\n",
       "      <td>37.334557</td>\n",
       "      <td>1.715138</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.978243</td>\n",
       "      <td>1.164101</td>\n",
       "      <td>1.116466</td>\n",
       "      <td>0.042666</td>\n",
       "      <td>False</td>\n",
       "      <td>39.032138</td>\n",
       "      <td>1.697281</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.799305</td>\n",
       "      <td>0.937791</td>\n",
       "      <td>0.937791</td>\n",
       "      <td>-0.160037</td>\n",
       "      <td>True</td>\n",
       "      <td>40.734265</td>\n",
       "      <td>1.702035</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.900172</td>\n",
       "      <td>1.064285</td>\n",
       "      <td>0.937791</td>\n",
       "      <td>0.134886</td>\n",
       "      <td>False</td>\n",
       "      <td>42.429585</td>\n",
       "      <td>1.695029</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.735702</td>\n",
       "      <td>0.911364</td>\n",
       "      <td>0.911364</td>\n",
       "      <td>-0.028180</td>\n",
       "      <td>True</td>\n",
       "      <td>44.137951</td>\n",
       "      <td>1.708274</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1.146747</td>\n",
       "      <td>1.329942</td>\n",
       "      <td>0.911364</td>\n",
       "      <td>0.459288</td>\n",
       "      <td>False</td>\n",
       "      <td>45.856591</td>\n",
       "      <td>1.718349</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.681986</td>\n",
       "      <td>0.870155</td>\n",
       "      <td>0.870155</td>\n",
       "      <td>-0.045217</td>\n",
       "      <td>True</td>\n",
       "      <td>47.554615</td>\n",
       "      <td>1.697940</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.889877</td>\n",
       "      <td>1.043369</td>\n",
       "      <td>0.870155</td>\n",
       "      <td>0.199062</td>\n",
       "      <td>False</td>\n",
       "      <td>49.257467</td>\n",
       "      <td>1.702569</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.623078</td>\n",
       "      <td>0.809624</td>\n",
       "      <td>0.809624</td>\n",
       "      <td>-0.069563</td>\n",
       "      <td>True</td>\n",
       "      <td>50.968785</td>\n",
       "      <td>1.711226</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.616201</td>\n",
       "      <td>0.854710</td>\n",
       "      <td>0.809624</td>\n",
       "      <td>0.055688</td>\n",
       "      <td>False</td>\n",
       "      <td>52.674206</td>\n",
       "      <td>1.705129</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.524319</td>\n",
       "      <td>0.745144</td>\n",
       "      <td>0.745144</td>\n",
       "      <td>-0.079641</td>\n",
       "      <td>True</td>\n",
       "      <td>54.374398</td>\n",
       "      <td>1.700108</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.505913</td>\n",
       "      <td>0.751899</td>\n",
       "      <td>0.745144</td>\n",
       "      <td>0.009065</td>\n",
       "      <td>False</td>\n",
       "      <td>56.066991</td>\n",
       "      <td>1.692302</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.474497</td>\n",
       "      <td>0.725291</td>\n",
       "      <td>0.725291</td>\n",
       "      <td>-0.026644</td>\n",
       "      <td>True</td>\n",
       "      <td>57.757491</td>\n",
       "      <td>1.690408</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.459235</td>\n",
       "      <td>0.746134</td>\n",
       "      <td>0.725291</td>\n",
       "      <td>0.028738</td>\n",
       "      <td>False</td>\n",
       "      <td>59.448550</td>\n",
       "      <td>1.690767</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.523776</td>\n",
       "      <td>0.837726</td>\n",
       "      <td>0.725291</td>\n",
       "      <td>0.155022</td>\n",
       "      <td>False</td>\n",
       "      <td>61.148992</td>\n",
       "      <td>1.700342</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.417842</td>\n",
       "      <td>0.721271</td>\n",
       "      <td>0.721271</td>\n",
       "      <td>-0.005542</td>\n",
       "      <td>True</td>\n",
       "      <td>62.845455</td>\n",
       "      <td>1.696372</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.350622</td>\n",
       "      <td>0.663873</td>\n",
       "      <td>0.663873</td>\n",
       "      <td>-0.079578</td>\n",
       "      <td>True</td>\n",
       "      <td>64.540226</td>\n",
       "      <td>1.694478</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.388312</td>\n",
       "      <td>0.715543</td>\n",
       "      <td>0.663873</td>\n",
       "      <td>0.077831</td>\n",
       "      <td>False</td>\n",
       "      <td>66.239216</td>\n",
       "      <td>1.698682</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.434323</td>\n",
       "      <td>0.856878</td>\n",
       "      <td>0.663873</td>\n",
       "      <td>0.290724</td>\n",
       "      <td>False</td>\n",
       "      <td>67.929057</td>\n",
       "      <td>1.689749</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.606934</td>\n",
       "      <td>0.946155</td>\n",
       "      <td>0.663873</td>\n",
       "      <td>0.425204</td>\n",
       "      <td>False</td>\n",
       "      <td>69.617122</td>\n",
       "      <td>1.687973</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.362966</td>\n",
       "      <td>0.711233</td>\n",
       "      <td>0.663873</td>\n",
       "      <td>0.071339</td>\n",
       "      <td>False</td>\n",
       "      <td>71.307880</td>\n",
       "      <td>1.690658</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.476998</td>\n",
       "      <td>0.850972</td>\n",
       "      <td>0.663873</td>\n",
       "      <td>0.281828</td>\n",
       "      <td>False</td>\n",
       "      <td>73.003176</td>\n",
       "      <td>1.695204</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.484428</td>\n",
       "      <td>0.900602</td>\n",
       "      <td>0.663873</td>\n",
       "      <td>0.356587</td>\n",
       "      <td>False</td>\n",
       "      <td>74.694369</td>\n",
       "      <td>1.691109</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.276986</td>\n",
       "      <td>0.734629</td>\n",
       "      <td>0.663873</td>\n",
       "      <td>0.106580</td>\n",
       "      <td>False</td>\n",
       "      <td>76.388188</td>\n",
       "      <td>1.693728</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.350959</td>\n",
       "      <td>0.792116</td>\n",
       "      <td>0.663873</td>\n",
       "      <td>0.193174</td>\n",
       "      <td>False</td>\n",
       "      <td>78.075494</td>\n",
       "      <td>1.687214</td>\n",
       "      <td>73597440</td>\n",
       "      <td>159383552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss  best_val_loss  delta_per_best  saved_model  \\\n",
       "0       0    1.944045  1.944432       1.944432        0.000000         True   \n",
       "1       1    1.941513  1.942414       1.942414       -0.001038         True   \n",
       "2       2    1.935181  1.938070       1.938070       -0.002236         True   \n",
       "3       3    1.878736  1.896016       1.896016       -0.021699         True   \n",
       "4       4    1.709899  1.744386       1.744386       -0.079973         True   \n",
       "5       5    1.669752  1.699744       1.699744       -0.025592         True   \n",
       "6       6    1.648135  1.686584       1.686584       -0.007742         True   \n",
       "7       7    1.610812  1.645744       1.645744       -0.024215         True   \n",
       "8       8    1.568820  1.613060       1.613060       -0.019860         True   \n",
       "9       9    1.547423  1.586713       1.586713       -0.016333         True   \n",
       "10     10    1.519211  1.552478       1.552478       -0.021576         True   \n",
       "11     11    1.732850  1.775037       1.552478        0.143357        False   \n",
       "12     12    1.476497  1.527909       1.527909       -0.015826         True   \n",
       "13     13    1.473043  1.548228       1.527909        0.013299        False   \n",
       "14     14    1.651360  1.678878       1.527909        0.098807        False   \n",
       "15     15    1.352985  1.424677       1.424677       -0.067564         True   \n",
       "16     16    1.678987  1.718448       1.424677        0.206202        False   \n",
       "17     17    1.291691  1.377351       1.377351       -0.033219         True   \n",
       "18     18    1.211967  1.306961       1.306961       -0.051105         True   \n",
       "19     19    1.134376  1.225562       1.225562       -0.062281         True   \n",
       "20     20    1.048499  1.170474       1.170474       -0.044949         True   \n",
       "21     21    1.001748  1.116466       1.116466       -0.046142         True   \n",
       "22     22    0.978243  1.164101       1.116466        0.042666        False   \n",
       "23     23    0.799305  0.937791       0.937791       -0.160037         True   \n",
       "24     24    0.900172  1.064285       0.937791        0.134886        False   \n",
       "25     25    0.735702  0.911364       0.911364       -0.028180         True   \n",
       "26     26    1.146747  1.329942       0.911364        0.459288        False   \n",
       "27     27    0.681986  0.870155       0.870155       -0.045217         True   \n",
       "28     28    0.889877  1.043369       0.870155        0.199062        False   \n",
       "29     29    0.623078  0.809624       0.809624       -0.069563         True   \n",
       "30     30    0.616201  0.854710       0.809624        0.055688        False   \n",
       "31     31    0.524319  0.745144       0.745144       -0.079641         True   \n",
       "32     32    0.505913  0.751899       0.745144        0.009065        False   \n",
       "33     33    0.474497  0.725291       0.725291       -0.026644         True   \n",
       "34     34    0.459235  0.746134       0.725291        0.028738        False   \n",
       "35     35    0.523776  0.837726       0.725291        0.155022        False   \n",
       "36     36    0.417842  0.721271       0.721271       -0.005542         True   \n",
       "37     37    0.350622  0.663873       0.663873       -0.079578         True   \n",
       "38     38    0.388312  0.715543       0.663873        0.077831        False   \n",
       "39     39    0.434323  0.856878       0.663873        0.290724        False   \n",
       "40     40    0.606934  0.946155       0.663873        0.425204        False   \n",
       "41     41    0.362966  0.711233       0.663873        0.071339        False   \n",
       "42     42    0.476998  0.850972       0.663873        0.281828        False   \n",
       "43     43    0.484428  0.900602       0.663873        0.356587        False   \n",
       "44     44    0.276986  0.734629       0.663873        0.106580        False   \n",
       "45     45    0.350959  0.792116       0.663873        0.193174        False   \n",
       "\n",
       "    elapsed_time  epoch_time  cuda_mem_alloc  cuda_mem_cached  \n",
       "0       1.719959    1.719750        73597440        159383552  \n",
       "1       3.416122    1.695755        73597440        159383552  \n",
       "2       5.111468    1.695062        73597440        159383552  \n",
       "3       6.805496    1.693736        73597440        159383552  \n",
       "4       8.499399    1.693619        73597440        159383552  \n",
       "5      10.189940    1.690258        73597440        159383552  \n",
       "6      11.885094    1.694870        73597440        159383552  \n",
       "7      13.575628    1.690241        73597440        159383552  \n",
       "8      15.271691    1.695780        73597440        159383552  \n",
       "9      16.971641    1.699658        73597440        159383552  \n",
       "10     18.665402    1.693469        73597440        159383552  \n",
       "11     20.358454    1.692769        73597440        159383552  \n",
       "12     22.045985    1.687447        73597440        159383552  \n",
       "13     23.746710    1.700442        73597440        159383552  \n",
       "14     25.442898    1.696096        73597440        159383552  \n",
       "15     27.141163    1.698182        73597440        159383552  \n",
       "16     28.835183    1.693728        73597440        159383552  \n",
       "17     30.528552    1.693286        73597440        159383552  \n",
       "18     32.220704    1.691868        73597440        159383552  \n",
       "19     33.911296    1.690300        73597440        159383552  \n",
       "20     35.619127    1.707531        73597440        159383552  \n",
       "21     37.334557    1.715138        73597440        159383552  \n",
       "22     39.032138    1.697281        73597440        159383552  \n",
       "23     40.734265    1.702035        73597440        159383552  \n",
       "24     42.429585    1.695029        73597440        159383552  \n",
       "25     44.137951    1.708274        73597440        159383552  \n",
       "26     45.856591    1.718349        73597440        159383552  \n",
       "27     47.554615    1.697940        73597440        159383552  \n",
       "28     49.257467    1.702569        73597440        159383552  \n",
       "29     50.968785    1.711226        73597440        159383552  \n",
       "30     52.674206    1.705129        73597440        159383552  \n",
       "31     54.374398    1.700108        73597440        159383552  \n",
       "32     56.066991    1.692302        73597440        159383552  \n",
       "33     57.757491    1.690408        73597440        159383552  \n",
       "34     59.448550    1.690767        73597440        159383552  \n",
       "35     61.148992    1.700342        73597440        159383552  \n",
       "36     62.845455    1.696372        73597440        159383552  \n",
       "37     64.540226    1.694478        73597440        159383552  \n",
       "38     66.239216    1.698682        73597440        159383552  \n",
       "39     67.929057    1.689749        73597440        159383552  \n",
       "40     69.617122    1.687973        73597440        159383552  \n",
       "41     71.307880    1.690658        73597440        159383552  \n",
       "42     73.003176    1.695204        73597440        159383552  \n",
       "43     74.694369    1.691109        73597440        159383552  \n",
       "44     76.388188    1.693728        73597440        159383552  \n",
       "45     78.075494    1.687214        73597440        159383552  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_vs_epoch(dfp_train_results, output_path, fname='loss_vs_epoch', tag='_val', inline=False,\n",
    "                   ann_text_std_add=None,\n",
    "                   y_axis_params={'log': False},\n",
    "                   loss_cols=['val_loss'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_vs_epoch(dfp_train_results, output_path, fname='loss_vs_epoch', tag='_train', inline=False,\n",
    "                   ann_text_std_add=None,\n",
    "                   y_axis_params={'log': False},\n",
    "                   loss_cols=['train_loss'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_vs_epoch(dfp_train_results, output_path, fname='loss_vs_epoch', tag='', inline=False,\n",
    "                   ann_text_std_add=None,\n",
    "                   y_axis_params={'log': False},\n",
    "                   loss_cols=['train_loss', 'val_loss'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = dfp_train_results.iloc[dfp_train_results['val_loss'].idxmin()]['epoch']\n",
    "load_model(model, device, best_epoch, model_name, models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data again, with paths\n",
    "Non-standard but needed to see what images scored high or low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_with_paths_val = ImageFolderWithPaths(root=f'{data_path}/preprocessed/im_res_{im_res}/val', transform=transform)\n",
    "dl_with_paths_val = torch.utils.data.DataLoader(ds_with_paths_val, batch_size=batch_size, shuffle=True, pin_memory=pin_memory, num_workers=8)\n",
    "\n",
    "ds_with_paths_test = ImageFolderWithPaths(root=f'{data_path}/preprocessed/im_res_{im_res}/test', transform=transform)\n",
    "dl_with_paths_test = torch.utils.data.DataLoader(ds_with_paths_test, batch_size=batch_size, shuffle=False, pin_memory=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on Reweighting\n",
    "We must reweight the confusion matrix to account for different numbers of samples coming from each parent EKG. This avoids biasing the results in favor of longer recordings which generated more samples in the preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_preds_dfp(dl_with_paths, model, device):\n",
    "    l, p, f = get_preds(dl_with_paths, model, device, return_fnames=True)\n",
    "\n",
    "    dfp = pd.DataFrame({'label': l, 'pred': p, 'fname': f})\n",
    "\n",
    "    dfp['is_correct'] = 0\n",
    "    dfp.loc[dfp['label'] == dfp['pred'], 'is_correct'] = 1\n",
    "\n",
    "    dfp['parent_ekg'] = dfp['fname'].str.replace('-s\\d{2}_PIL\\.png', '')\n",
    "    dfp['parent_ekg_count'] = dfp.groupby(['parent_ekg'])['parent_ekg'].transform('size')\n",
    "    dfp['weight'] = 1.0/dfp['parent_ekg_count']\n",
    "\n",
    "    dfp = dfp.drop(columns=['parent_ekg', 'parent_ekg_count'])\n",
    "\n",
    "    dfp = massage_dfp(dfp, target_fixed_cols=['label', 'pred', 'is_correct', 'fname', 'weight'],\n",
    "                      sort_by=['label', 'is_correct', 'pred', 'fname'], sort_by_ascending=[True, False, True, True])\n",
    "\n",
    "    return dfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_preds_val = _make_preds_dfp(dl_with_paths_val, model, device)\n",
    "write_dfp(dfp_preds_val, output_path, 'preds', tag='_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>fname</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0007-s00_PIL.png</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0153-s00_PIL.png</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0153-s01_PIL.png</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0153-s02_PIL.png</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0153-s03_PIL.png</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>A4455-s01_PIL.png</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>A4478-s02_PIL.png</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>A4541-s01_PIL.png</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>A4935-s05_PIL.png</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3270</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A2304-s02_PIL.png</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3271 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  pred  is_correct              fname    weight\n",
       "0         0     0           1  A0007-s00_PIL.png  0.333333\n",
       "1         0     0           1  A0153-s00_PIL.png  0.250000\n",
       "2         0     0           1  A0153-s01_PIL.png  0.250000\n",
       "3         0     0           1  A0153-s02_PIL.png  0.250000\n",
       "4         0     0           1  A0153-s03_PIL.png  0.250000\n",
       "...     ...   ...         ...                ...       ...\n",
       "3266      6     4           0  A4455-s01_PIL.png  0.333333\n",
       "3267      6     4           0  A4478-s02_PIL.png  0.333333\n",
       "3268      6     4           0  A4541-s01_PIL.png  0.333333\n",
       "3269      6     4           0  A4935-s05_PIL.png  0.111111\n",
       "3270      6     5           0  A2304-s02_PIL.png  0.333333\n",
       "\n",
       "[3271 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_preds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_val = confusion_matrix(y_true=dfp_preds_val['label'], y_pred=dfp_preds_val['pred'], labels=[class_to_idx[k] for k in Dx_classes.keys()], sample_weight=dfp_preds_val['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = {'_val': True, '_raw_val': False}\n",
    "for tag,norm in cms.items():\n",
    "    plot_confusion_matrix(conf_matrix_val, label_names=Dx_classes.keys(),\n",
    "                          m_path=output_path, tag=tag, inline=False,\n",
    "                          ann_text_std_add=None,\n",
    "                          normalize=norm, weighted=not norm,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_preds_test = _make_preds_dfp(dl_with_paths_test, model, device)\n",
    "write_dfp(dfp_preds_test, output_path, 'preds', tag='_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>fname</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0004-s01_PIL.png</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0004-s02_PIL.png</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0220-s00_PIL.png</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0220-s01_PIL.png</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0220-s02_PIL.png</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3306</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A0930-s02_PIL.png</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A0930-s03_PIL.png</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A1479-s05_PIL.png</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A5106-s02_PIL.png</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A5106-s03_PIL.png</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3311 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  pred  is_correct              fname    weight\n",
       "0         0     0           1  A0004-s01_PIL.png  0.333333\n",
       "1         0     0           1  A0004-s02_PIL.png  0.333333\n",
       "2         0     0           1  A0220-s00_PIL.png  0.125000\n",
       "3         0     0           1  A0220-s01_PIL.png  0.125000\n",
       "4         0     0           1  A0220-s02_PIL.png  0.125000\n",
       "...     ...   ...         ...                ...       ...\n",
       "3306      6     5           0  A0930-s02_PIL.png  0.250000\n",
       "3307      6     5           0  A0930-s03_PIL.png  0.250000\n",
       "3308      6     5           0  A1479-s05_PIL.png  0.100000\n",
       "3309      6     5           0  A5106-s02_PIL.png  0.250000\n",
       "3310      6     5           0  A5106-s03_PIL.png  0.250000\n",
       "\n",
       "[3311 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_test = confusion_matrix(y_true=dfp_preds_test['label'], y_pred=dfp_preds_test['pred'], labels=[class_to_idx[k] for k in Dx_classes.keys()], sample_weight=dfp_preds_test['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = {'_test': True, '_raw_test': False}\n",
    "for tag,norm in cms.items():\n",
    "    plot_confusion_matrix(conf_matrix_test, label_names=Dx_classes.keys(),\n",
    "                          m_path=output_path, tag=tag, inline=False,\n",
    "                          ann_text_std_add=None,\n",
    "                          normalize=norm, weighted=not norm,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [32, 16, 400, 400]             144\n",
      "       BatchNorm2d-2         [32, 16, 400, 400]              32\n",
      "             ReLU6-3         [32, 16, 400, 400]               0\n",
      "         h_sigmoid-4         [32, 16, 400, 400]               0\n",
      "           h_swish-5         [32, 16, 400, 400]               0\n",
      "            Conv2d-6         [32, 16, 200, 200]             144\n",
      "       BatchNorm2d-7         [32, 16, 200, 200]              32\n",
      "              ReLU-8         [32, 16, 200, 200]               0\n",
      " AdaptiveAvgPool2d-9             [32, 16, 1, 1]               0\n",
      "           Linear-10                    [32, 8]             136\n",
      "             ReLU-11                    [32, 8]               0\n",
      "           Linear-12                   [32, 16]             144\n",
      "            ReLU6-13                   [32, 16]               0\n",
      "        h_sigmoid-14                   [32, 16]               0\n",
      "          SELayer-15         [32, 16, 200, 200]               0\n",
      "           Conv2d-16          [32, 8, 200, 200]             128\n",
      "      BatchNorm2d-17          [32, 8, 200, 200]              16\n",
      " InvertedResidual-18          [32, 8, 200, 200]               0\n",
      "           Conv2d-19         [32, 40, 200, 200]             320\n",
      "      BatchNorm2d-20         [32, 40, 200, 200]              80\n",
      "             ReLU-21         [32, 40, 200, 200]               0\n",
      "           Conv2d-22         [32, 40, 100, 100]             360\n",
      "      BatchNorm2d-23         [32, 40, 100, 100]              80\n",
      "         Identity-24         [32, 40, 100, 100]               0\n",
      "             ReLU-25         [32, 40, 100, 100]               0\n",
      "           Conv2d-26          [32, 8, 100, 100]             320\n",
      "      BatchNorm2d-27          [32, 8, 100, 100]              16\n",
      " InvertedResidual-28          [32, 8, 100, 100]               0\n",
      "           Conv2d-29         [32, 32, 100, 100]             256\n",
      "      BatchNorm2d-30         [32, 32, 100, 100]              64\n",
      "             ReLU-31         [32, 32, 100, 100]               0\n",
      "           Conv2d-32         [32, 32, 100, 100]             288\n",
      "      BatchNorm2d-33         [32, 32, 100, 100]              64\n",
      "         Identity-34         [32, 32, 100, 100]               0\n",
      "             ReLU-35         [32, 32, 100, 100]               0\n",
      "           Conv2d-36          [32, 8, 100, 100]             256\n",
      "      BatchNorm2d-37          [32, 8, 100, 100]              16\n",
      " InvertedResidual-38          [32, 8, 100, 100]               0\n",
      "           Conv2d-39         [32, 32, 100, 100]             256\n",
      "      BatchNorm2d-40         [32, 32, 100, 100]              64\n",
      "            ReLU6-41         [32, 32, 100, 100]               0\n",
      "        h_sigmoid-42         [32, 32, 100, 100]               0\n",
      "          h_swish-43         [32, 32, 100, 100]               0\n",
      "           Conv2d-44           [32, 32, 50, 50]             800\n",
      "      BatchNorm2d-45           [32, 32, 50, 50]              64\n",
      "AdaptiveAvgPool2d-46             [32, 32, 1, 1]               0\n",
      "           Linear-47                    [32, 8]             264\n",
      "             ReLU-48                    [32, 8]               0\n",
      "           Linear-49                   [32, 32]             288\n",
      "            ReLU6-50                   [32, 32]               0\n",
      "        h_sigmoid-51                   [32, 32]               0\n",
      "          SELayer-52           [32, 32, 50, 50]               0\n",
      "            ReLU6-53           [32, 32, 50, 50]               0\n",
      "        h_sigmoid-54           [32, 32, 50, 50]               0\n",
      "          h_swish-55           [32, 32, 50, 50]               0\n",
      "           Conv2d-56           [32, 16, 50, 50]             512\n",
      "      BatchNorm2d-57           [32, 16, 50, 50]              32\n",
      " InvertedResidual-58           [32, 16, 50, 50]               0\n",
      "           Conv2d-59           [32, 96, 50, 50]           1,536\n",
      "      BatchNorm2d-60           [32, 96, 50, 50]             192\n",
      "            ReLU6-61           [32, 96, 50, 50]               0\n",
      "        h_sigmoid-62           [32, 96, 50, 50]               0\n",
      "          h_swish-63           [32, 96, 50, 50]               0\n",
      "           Conv2d-64           [32, 96, 50, 50]           2,400\n",
      "      BatchNorm2d-65           [32, 96, 50, 50]             192\n",
      "AdaptiveAvgPool2d-66             [32, 96, 1, 1]               0\n",
      "           Linear-67                   [32, 24]           2,328\n",
      "             ReLU-68                   [32, 24]               0\n",
      "           Linear-69                   [32, 96]           2,400\n",
      "            ReLU6-70                   [32, 96]               0\n",
      "        h_sigmoid-71                   [32, 96]               0\n",
      "          SELayer-72           [32, 96, 50, 50]               0\n",
      "            ReLU6-73           [32, 96, 50, 50]               0\n",
      "        h_sigmoid-74           [32, 96, 50, 50]               0\n",
      "          h_swish-75           [32, 96, 50, 50]               0\n",
      "           Conv2d-76           [32, 16, 50, 50]           1,536\n",
      "      BatchNorm2d-77           [32, 16, 50, 50]              32\n",
      " InvertedResidual-78           [32, 16, 50, 50]               0\n",
      "           Conv2d-79           [32, 96, 50, 50]           1,536\n",
      "      BatchNorm2d-80           [32, 96, 50, 50]             192\n",
      "            ReLU6-81           [32, 96, 50, 50]               0\n",
      "        h_sigmoid-82           [32, 96, 50, 50]               0\n",
      "          h_swish-83           [32, 96, 50, 50]               0\n",
      "           Conv2d-84           [32, 96, 50, 50]           2,400\n",
      "      BatchNorm2d-85           [32, 96, 50, 50]             192\n",
      "AdaptiveAvgPool2d-86             [32, 96, 1, 1]               0\n",
      "           Linear-87                   [32, 24]           2,328\n",
      "             ReLU-88                   [32, 24]               0\n",
      "           Linear-89                   [32, 96]           2,400\n",
      "            ReLU6-90                   [32, 96]               0\n",
      "        h_sigmoid-91                   [32, 96]               0\n",
      "          SELayer-92           [32, 96, 50, 50]               0\n",
      "            ReLU6-93           [32, 96, 50, 50]               0\n",
      "        h_sigmoid-94           [32, 96, 50, 50]               0\n",
      "          h_swish-95           [32, 96, 50, 50]               0\n",
      "           Conv2d-96           [32, 32, 50, 50]           3,072\n",
      "      BatchNorm2d-97           [32, 32, 50, 50]              64\n",
      " InvertedResidual-98           [32, 32, 50, 50]               0\n",
      "           Conv2d-99           [32, 96, 50, 50]           3,072\n",
      "     BatchNorm2d-100           [32, 96, 50, 50]             192\n",
      "           ReLU6-101           [32, 96, 50, 50]               0\n",
      "       h_sigmoid-102           [32, 96, 50, 50]               0\n",
      "         h_swish-103           [32, 96, 50, 50]               0\n",
      "          Conv2d-104           [32, 96, 50, 50]           2,400\n",
      "     BatchNorm2d-105           [32, 96, 50, 50]             192\n",
      "AdaptiveAvgPool2d-106             [32, 96, 1, 1]               0\n",
      "          Linear-107                   [32, 24]           2,328\n",
      "            ReLU-108                   [32, 24]               0\n",
      "          Linear-109                   [32, 96]           2,400\n",
      "           ReLU6-110                   [32, 96]               0\n",
      "       h_sigmoid-111                   [32, 96]               0\n",
      "         SELayer-112           [32, 96, 50, 50]               0\n",
      "           ReLU6-113           [32, 96, 50, 50]               0\n",
      "       h_sigmoid-114           [32, 96, 50, 50]               0\n",
      "         h_swish-115           [32, 96, 50, 50]               0\n",
      "          Conv2d-116           [32, 32, 50, 50]           3,072\n",
      "     BatchNorm2d-117           [32, 32, 50, 50]              64\n",
      "InvertedResidual-118           [32, 32, 50, 50]               0\n",
      "          Conv2d-119           [32, 96, 50, 50]           3,072\n",
      "     BatchNorm2d-120           [32, 96, 50, 50]             192\n",
      "           ReLU6-121           [32, 96, 50, 50]               0\n",
      "       h_sigmoid-122           [32, 96, 50, 50]               0\n",
      "         h_swish-123           [32, 96, 50, 50]               0\n",
      "AdaptiveAvgPool2d-124             [32, 96, 1, 1]               0\n",
      "          Linear-125                 [32, 1024]          99,328\n",
      "           ReLU6-126                 [32, 1024]               0\n",
      "       h_sigmoid-127                 [32, 1024]               0\n",
      "         h_swish-128                 [32, 1024]               0\n",
      "         Dropout-129                 [32, 1024]               0\n",
      "          Linear-130                    [32, 7]           7,175\n",
      "     MobileNetV3-131                    [32, 7]               0\n",
      "================================================================\n",
      "Total params: 151,463\n",
      "Trainable params: 151,463\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 78.12\n",
      "Forward/backward pass size (MB): 9122.74\n",
      "Params size (MB): 0.58\n",
      "Estimated Total Size (MB): 9201.45\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(models_path, 'model_summary.txt'), 'r') as f:\n",
    "    summary_str = f.read()\n",
    "    print(summary_str)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.eval of MobileNetV3(\n",
      "  (features): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): h_swish(\n",
      "        (sigmoid): h_sigmoid(\n",
      "          (relu): ReLU6(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=16, out_features=8, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=8, out_features=16, bias=True)\n",
      "            (3): h_sigmoid(\n",
      "              (relu): ReLU6(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(8, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)\n",
      "        (4): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Identity()\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): Conv2d(40, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Identity()\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): h_swish(\n",
      "          (sigmoid): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (3): Conv2d(32, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=32, out_features=8, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=8, out_features=32, bias=True)\n",
      "            (3): h_sigmoid(\n",
      "              (relu): ReLU6(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): h_swish(\n",
      "          (sigmoid): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): h_swish(\n",
      "          (sigmoid): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (3): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=96, out_features=24, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=24, out_features=96, bias=True)\n",
      "            (3): h_sigmoid(\n",
      "              (relu): ReLU6(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): h_swish(\n",
      "          (sigmoid): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): h_swish(\n",
      "          (sigmoid): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (3): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=96, out_features=24, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=24, out_features=96, bias=True)\n",
      "            (3): h_sigmoid(\n",
      "              (relu): ReLU6(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): h_swish(\n",
      "          (sigmoid): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): h_swish(\n",
      "          (sigmoid): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (3): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=96, out_features=24, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=24, out_features=96, bias=True)\n",
      "            (3): h_sigmoid(\n",
      "              (relu): ReLU6(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): h_swish(\n",
      "          (sigmoid): h_sigmoid(\n",
      "            (relu): ReLU6(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (7): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): h_swish(\n",
      "      (sigmoid): h_sigmoid(\n",
      "        (relu): ReLU6(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=96, out_features=1024, bias=True)\n",
      "    (1): h_swish(\n",
      "      (sigmoid): h_sigmoid(\n",
      "        (relu): ReLU6(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=1024, out_features=7, bias=True)\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(models_path, 'model_eval.txt'), 'r') as f:\n",
    "    model_eval_str = f.read()\n",
    "    print(model_eval_str)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Compute Accuracy, F1 Scores per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class = {\n",
    "0: 'AF',\n",
    "1: 'I-AVB',\n",
    "2: 'LBBB',\n",
    "3: 'Normal',\n",
    "4: 'RBBB',\n",
    "5: 'STD',\n",
    "6: 'STE',\n",
    "}\n",
    "class_to_idx = dict([[v,k] for k,v in idx_to_class.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_preds_test = load_dfp(os.path.expanduser('~/mount_sinai_health_hackathon_ekg_img/modeling/SAVED_RESULTS/2020-07-16_mobilenetv3_small_custom_800_best/output'), 'preds', tag='_test', cols_str=['fname'], cols_float=['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>fname</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0004-s01_PIL.png</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0004-s02_PIL.png</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0220-s00_PIL.png</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0220-s01_PIL.png</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0220-s02_PIL.png</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3306</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A0930-s02_PIL.png</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A0930-s03_PIL.png</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A1479-s05_PIL.png</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A5106-s02_PIL.png</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A5106-s03_PIL.png</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3311 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  pred  is_correct              fname    weight\n",
       "0         0     0           1  A0004-s01_PIL.png  0.333333\n",
       "1         0     0           1  A0004-s02_PIL.png  0.333333\n",
       "2         0     0           1  A0220-s00_PIL.png  0.125000\n",
       "3         0     0           1  A0220-s01_PIL.png  0.125000\n",
       "4         0     0           1  A0220-s02_PIL.png  0.125000\n",
       "...     ...   ...         ...                ...       ...\n",
       "3306      6     5           0  A0930-s02_PIL.png  0.250000\n",
       "3307      6     5           0  A0930-s03_PIL.png  0.250000\n",
       "3308      6     5           0  A1479-s05_PIL.png  0.100000\n",
       "3309      6     5           0  A5106-s02_PIL.png  0.250000\n",
       "3310      6     5           0  A5106-s03_PIL.png  0.250000\n",
       "\n",
       "[3311 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal      0.710     0.679     0.694 137.00000000000006\n",
      "          AF      0.907     0.870     0.888 145.99999999999972\n",
      "       I-AVB      0.712     0.857     0.778 102.00000000000006\n",
      "        LBBB      0.711     0.853     0.775 25.999999999999996\n",
      "        RBBB      0.892     0.826     0.858 229.00000000000065\n",
      "         STD      0.728     0.731     0.729 116.99999999999996\n",
      "         STE      0.525     0.572     0.547 26.999999999999982\n",
      "\n",
      "    accuracy                          0.790 784.0000000000005\n",
      "   macro avg      0.741     0.770     0.753 784.0000000000005\n",
      "weighted avg      0.796     0.790     0.792 784.0000000000005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_true=dfp_preds_test['label'], y_pred=dfp_preds_test['pred'], sample_weight=dfp_preds_test['weight'], labels=[class_to_idx[k] for k in Dx_classes.keys()], target_names=Dx_classes.keys(), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal': {'precision': 0.7095213163573207,\n",
       "  'recall': 0.6790783223264978,\n",
       "  'f1-score': 0.6939661105248599,\n",
       "  'support': 137.00000000000006},\n",
       " 'AF': {'precision': 0.9065493579726872,\n",
       "  'recall': 0.8704174820613165,\n",
       "  'f1-score': 0.8881160770741112,\n",
       "  'support': 145.99999999999972},\n",
       " 'I-AVB': {'precision': 0.7119610912054251,\n",
       "  'recall': 0.8565359477124189,\n",
       "  'f1-score': 0.7775854883484398,\n",
       "  'support': 102.00000000000006},\n",
       " 'LBBB': {'precision': 0.7107864968379806,\n",
       "  'recall': 0.8525641025641029,\n",
       "  'f1-score': 0.7752465147908881,\n",
       "  'support': 25.999999999999996},\n",
       " 'RBBB': {'precision': 0.892211083039455,\n",
       "  'recall': 0.8255302557704289,\n",
       "  'f1-score': 0.8575764312606932,\n",
       "  'support': 229.00000000000065},\n",
       " 'STD': {'precision': 0.7278168871353484,\n",
       "  'recall': 0.7307692307692317,\n",
       "  'f1-score': 0.729290071013208,\n",
       "  'support': 116.99999999999996},\n",
       " 'STE': {'precision': 0.5248230774415316,\n",
       "  'recall': 0.5722222222222226,\n",
       "  'f1-score': 0.5474986816663739,\n",
       "  'support': 26.999999999999982},\n",
       " 'accuracy': 0.7903628117913839,\n",
       " 'macro avg': {'precision': 0.7405241871413927,\n",
       "  'recall': 0.7695882233466028,\n",
       "  'f1-score': 0.7527541963826535,\n",
       "  'support': 784.0000000000005},\n",
       " 'weighted avg': {'precision': 0.7963038823054828,\n",
       "  'recall': 0.790362811791383,\n",
       "  'f1-score': 0.7917128049273804,\n",
       "  'support': 784.0000000000005}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_true=dfp_preds_test['label'], y_pred=dfp_preds_test['pred'], sample_weight=dfp_preds_test['weight'], labels=[class_to_idx[k] for k in Dx_classes.keys()], target_names=Dx_classes.keys(), digits=3, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_code import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mem(print_objects=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
